<pre class='metadata'>
Title: Private Aggregation API
Shortname: private-aggregation-api
Level: 1
Status: w3c/CG-DRAFT
Group: patcg
Repository: patcg-individual-drafts/private-aggregation-api
URL: https://patcg-individual-drafts.github.io/private-aggregation-api
Editor: Alexander Turner, Google https://www.google.com, alexmt@chromium.org
Abstract: A generic API for measuring aggregate, cross-site data in a privacy
    preserving manner. The potentially identifying cross-site data is
    encapsulated into <em>aggregatable reports</em>. To prevent leakage, this
    data is encrypted, ensuring it can only be processed by an <em>aggregation
    service</em>. During processing, this service will add noise and impose
    limits on how many queries can be performed.

<!--- Warning: Not Ready -->
Markup Shorthands: markdown on
Complain About: accidental-2119 on, missing-example-ids on
Assume Explicit For: on
</pre>

<pre class="anchors">
urlPrefix: https://wicg.github.io/turtledove/; type: interface
    text: InterestGroupBiddingScriptRunnerGlobalScope
    text: InterestGroupScriptRunnerGlobalScope
    text: InterestGroupScoringScriptRunnerGlobalScope
    text: InterestGroupReportingScriptRunnerGlobalScope
urlPrefix: https://wicg.github.io/shared-storage/; type: interface
    text: SharedStorageWorklet
    text: SharedStorageWorkletGlobalScope
spec: hr-time; type: dfn; urlPrefix: https://w3c.github.io/hr-time/
    text: current wall time; url: #dfn-current-wall-time
    text: duration; url: #dfn-duration
    text: duration from; url: #dfn-duration-from
    text: moment; url: #dfn-moment
    text: unix epoch; url: #dfn-unix-epoch
    text: wall clock; url: #dfn-wall-clock
</pre>

<pre class=link-defaults>
spec:infra; type:dfn; text:user agent
</pre>


Introduction {#intro}
=====================

<em>This section is non-normative.</em>

Motivation {#motivation}
------------------------

Browsers are now working to prevent cross-site user tracking, including by
partitioning storage and removing third-party cookies. There are a range of API
proposals to continue supporting legitimate use cases in a way that respects
user privacy. Many of these APIs, including the
<a href="https://wicg.github.io/shared-storage/">Shared Storage API</a> and the
<a href="https://wicg.github.io/turtledove/">Protected Audience API</a>, isolate
potentially identifying cross-site data in special contexts, which ensures that
the data cannot escape the user agent.

Relative to cross-site data from an individual user, aggregate data about groups
of users can be less sensitive and yet would be sufficient for a wide range of
use cases. An aggregation service has been proposed to allow reporting noisy,
aggregated cross-site data. This service was originally proposed for use by the
<a href="https://wicg.github.io/attribution-reporting-api/">Attribution
Reporting API</a>, but allowing more general aggregation would support
additional use cases. In particular, the Protected Audience and Shared Storage
proposals expect this functionality to become available.

Overview {#overview}
--------------------

This document oulines a general-purpose API that can be called from isolated
contexts that have access to cross-site data (such as a Shared Storage worklet).
Within these contexts, potentially identifying data can be encapsulated into
"aggregatable reports". To prevent leakage, the cross-site data in these reports
is encrypted to ensure it can only be processed by the aggregation service.
During processing, this service adds noise and imposes limits on how many
queries can be performed.

This API provides functions allowing the origin to construct an aggregatable
report and specify the values to be embedded into its encrypted payload (for
later computation via the aggregation service). These calls result in the
aggregatable report being queued to be sent to the reporting endpoint of the
script's origin after a delay. After the endpoint receives the reports, it will
batch the reports and send them to the aggregation service for processing. The
output of that process is a summary report containing the (approximate) result,
which is dispatched back to the script's origin.


General methods {#general-methods}
==================================

Worklet interface {#worklet-interface}
--------------------------------------

<xmp class="idl">
[Exposed=(InterestGroupScriptRunnerGlobalScope,SharedStorageWorklet),
 SecureContext]
interface PrivateAggregation {
  undefined sendHistogramReport(PAHistogramContribution contribution);
};

dictionary PAHistogramContribution {
  required bigint bucket;
  required long value;
};
</xmp>

Each {{PrivateAggregation}} has a <dfn>contributions cache</dfn>, a [=list=].
Each item must be either a {{PAHistogramContribution}} or a
{{PAExtendedHistogramContribution}}.

Note: The steps to process the [=contributions cache=] are defined separately
    for each [=context type=].

Issue: Do we need to spec enableDebugMode?

Issue: Need to spec Permissions Policy integration.

<div algorithm>
The <dfn method for="PrivateAggregation">
sendHistogramReport(PAHistogramContribution contribution)</dfn> method steps
are:
</div>

1. Throw {{RangeError}} if |contribution|["{{PAHistogramContribution/bucket}}"]
    is not in the range [0, 2<sup>128</sup>âˆ’1].
1. Throw {{RangeError}} if |contribution|["{{PAHistogramContribution/value}}"]
    is negative.
1. [=list/Append=] |contribution| to the [=contributions cache=].

Issue: Check that value can actually be zero in the spec pipeline.


Exposing to the Shared Storage API {#shared-storage}
====================================================

<xmp class="idl">
partial interface SharedStorageWorkletGlobalScope {
  readonly attribute PrivateAggregation privateAggregation;
};
</xmp>

Immediately after an operation completes, [=process the Shared Storage
contributions cache=] given the worklet's [=contributions cache=] and the
worklet's global scope.

Issue: How to handle batching different operation invocations properly. This
    doesn't work for simultaneous operations. Also disallow usage outside an
    operation.

To <dfn>process the Shared Storage contributions cache</dfn> given a [=list=]
|contributionsCache| and a {{SharedStorageWorkletGlobalScope}} |scope|, perform
the [=PrivateAggregation/report creation and scheduling steps=] with |scope|'s
[=relevant settings object=]'s [=environment settings object/origin=],
"<code>[=context type/shared-storage=]</code>" and |contributionsCache|.


Exposing to the Protected Audience API {#protected-audience}
============================================================

<xmp class="idl">
partial interface InterestGroupScriptRunnerGlobalScope {
  readonly attribute PrivateAggregation privateAggregation;
};

dictionary PASignalValue {
  required DOMString baseValue;
  double scale;
  (bigint or long) offset;
};

dictionary PAExtendedHistogramContribution {
  required (PASignalValue or bigint) bucket;
  required (PASignalValue or long) value;
};

[Exposed=InterestGroupScriptRunnerGlobalScope, SecureContext]
partial interface PrivateAggregation {
  undefined reportContributionForEvent(
      DOMString event, PAExtendedHistogramContribution contribution);
};
</xmp>

Issue: Do we want to align naming with implementation?

Immediately after an auction completes, [=process the Protected Audience
contributions cache=] given the worklet's [=contributions cache=] and the
worklet's global scope.

Issue: Does Protected Audience API have one global scope per auction or
    multiple? If multiple, will need to change scope for batching.

Issue: How to handle fenced frame-triggered contributions and other
    event-triggered contributions.

Issue: Need to handle `auctionReportBuyers` and `auctionReportBuyerKeys` here or
    in the Protected Audience API spec.

<div algorithm>
The <dfn method for="PrivateAggregation">reportContributionForEvent(DOMString
event, PAExtendedHistogramContribution contribution)</dfn> method steps are:
</div>

Issue: Fill in validation. Will need to check offsets are valid and in the right
    range for the type etc. Also that base values are one of a set.

Issue: Need to document limits on offset, etc.

Issue: Fill in the rest. (Need to put the contribution in some sort of queue and
    process the queue at some point. Need to decide where the queue should live
    given it has to outlive the auction.)

To <dfn>process the Protected Audience contributions cache</dfn> given a
[=list=] |contributionsCache| and a {{InterestGroupScriptRunnerGlobalScope}}
|scope|, perform the following steps:
1. Let |filledInContributions| be a new [=list/is empty|empty=] [=list=].
1. [=list/iterate|For each=] |contribution| of |contributionsCache|:
    1. [=list/Append=] the result of [=filling in the contribution=] given
        |contribution| to |filledInContributions|.
1. Perform the [=PrivateAggregation/report creation and scheduling steps=] with
    |scope|'s [=relevant settings object=]'s [=environment settings object/
    origin=], "<code>[=context type/fledge=]</code>" and
    |filledInContributions|.


Structures {#structures}
========================

General {#general-structures}
-----------------------------

<h4 dfn-type=dfn>Aggregatable report</h3>

An aggregatable report is a [=struct=] with the following items:
<dl dfn-for="aggregatable report">
: <dfn>reporting origin</dfn>
:: An [=origin=]
: <dfn>original report time</dfn>
:: A [=moment=]
: <dfn>report time</dfn>
:: A [=moment=]
: <dfn>contributions</dfn>
:: A [=list=] of {{PAHistogramContribution}}s
: <dfn>api</dfn>
:: A [=context type=]
: <dfn>report ID</dfn>
:: A [=string=]
: <dfn>queued</dfn>
:: A [=boolean=]

</dl>

Issue: Handle operation types, aggregation coordinators, maybe retries/offline,
    report verification

<h4 dfn-type=dfn>Context type</h3>
A context type is one of the following:
<dl dfn-for="context type">
: "<dfn><code>fledge</code></dfn>"
:: The global scope's [=global names=] [=list/contains=]
    {{InterestGroupScriptRunnerGlobalScope}}.
: "<dfn><code>shared-storage</code></dfn>"
:: The global scope's [=global names=] [=list/contains=]
    {{SharedStorageWorklet}}.

</dl>

Issue: Need to update "<code>[=context type/fledge=]</code>" to reflect API name
    change.

Protected Audience API-specific {#protected-audience-api-specific-structures}
-----------------------------------------------------------------------------

<h4 dfn-type=dfn>Signal base value</h3>
A signal base value is one of the following:
<dl dfn-for="signal base value">
: "<dfn export><code>winning-bid</code></dfn>"
:: The bid value of the winning bid.
: "<dfn export><code>highest-scoring-other-bid</code></dfn>"
:: The bid value of the highest scoring bid that did not win.
: "<dfn export><code>script-run-time</code></dfn>"
:: The running time of the script in ms(?).
: "<dfn export><code>signals-fetch-time</code></dfn>"
:: The time it took for the signals fetch to complete in ms(?)
: "<dfn export><code>bid-reject-reason</code></dfn>"
:: The reason a bid was rejected.

</dl>

Issue: Remove exports when these definitions are used.

Issue: Make sure these definitions match "determine the numeric value" algorithm

Issue: New enum needed for bid reject reasons.

Storage {#storage}
==================

A user agent holds an <dfn>aggregatable report cache</dfn>, which is a [=list=]
of [=aggregatable reports=].

[=Implementation-defined=] values {#implementation-defined-values}
==================================================================

<dfn>Maximum report contributions</dfn> is a positive integer that controls how
many contributions can be present in a single report.

<dfn>Minimum report delay</dfn> is a non-negative [=duration=] that controls the
minimum delay to deliver an [=aggregatable report=]

<dfn>Randomized report delay</dfn> is a positive [=duration=] that controls the
random delay to deliver an [=aggregatable report=]. This delay is additional to
the minimum delay.

Issue: More

Algorithms {#algorithms}
====================

To <dfn>serialize an integer</dfn>, represent it as a [=string=] of the shortest
possible decimal number.

Issue: This would ideally be replaced by a more descriptive algorithm in Infra.
    See infra/201

Scheduling reports {#scheduling-reports}
----------------------------------------

To perform the <dfn algorithm for="PrivateAggregation">report creation and
scheduling steps</dfn> with an [=origin=] |reportingOrigin|, a [=context type=]
|api| and a [=list=] of {{PAHistogramContribution}}s |contributions|:
1. [=Assert=]: |reportingOrigin| is a [=potentially trustworthy origin=].
1. Let |truncatedContributions| be a new [=list/is empty|empty=] [=list=].
1. If |contributions| has a [=list/size=] greater than [=maximum report
    contributions=]:
    1. [=set/For each=] |n| of [=the exclusive range|the range=] 0 to [=maximum
        report contributions=], exclusive:
        1. [=set/Append=] |contributions|[|n|] to |truncatedContributions|.
1. Otherwise, set |truncatedContributions| to |contributions|.
1. Let |contributionSum| be 0.
1. [=set/iterate|For each=] |contribution| of |truncatedContributions|:
    1. [=Assert=]: |contribution|["|value|"] is non-negative.
    1. Add |contribution|["|value|"] to |contributionSum|.
1. Let |currentWallTime| be the [=current wall time=].
1. Let |sufficientBudget| be the result of [=PrivateAggregation/consuming budget
    if permitted=] given |contributionSum|, |reportingOrigin|, |api| and
    |currentWallTime|.
1. If |sufficientBudget| is false, return.
1. Let |report| be the result of [=PrivateAggregation/obtaining an aggregatable
    report=] given |reportingOrigin|, |api|, |truncatedContributions| and
    |currentWallTime|.
1. [=set/Append=] |report| to the user agent's [=aggregatable report cache=].

Issue: Do we need to ensure the reports aren't queued after being sent?

Issue: Do we need to address user settings here at all?

To <dfn algorithm for="PrivateAggregation">consume budget if permitted</dfn>
given a {{long}} |value|, an [=origin=] <var ignore=''>origin</var>, a [=context
type=] |api| and a [=moment=] |currentTime|, perform [=implementation-defined=]
steps. They return a [=boolean=], which indicates whether there is sufficient
'contribution budget' left to send the requested contribution |value|. This
budget should be bound to usage over time, e.g. the contribution sum over the
last 24 hours. The algorithm should assume that the contribution will be sent if
and only if true is returned, i.e. it should consume the budget in that case.

To <dfn for="PrivateAggregation">obtain an aggregatable report</dfn> given an
[=origin=] |reportingOrigin|, a [=context type=] |api|, a [=list=] of
{{PAHistogramContribution}}s |contributions| and a [=moment=] |currentTime|,
perform the following steps. They return an [=aggregatable report=].
1. [=Assert=]: |reportingOrigin| is a [=potentially trustworthy origin=].
1. Let |reportTime| be the result of running [=PrivateAggregation/obtain a
    report delivery time=] given |currentTime|.
1. Let |report| be a new [=aggregatable report=] with the items:
    : [=aggregatable report/reporting origin=]
    :: |reportingOrigin|
    : [=aggregatable report/original report time=]
    :: |reportTime|
    : [=aggregatable report/report time=]
    :: |reportTime|
    : [=aggregatable report/contributions=]
    :: |contributions|
    : [=aggregatable report/api=]
    :: |api|
    : [=aggregatable report/report ID=]
    :: The result of [=generating a random UUID=].
    : [=aggregatable report/queued=]
    :: false
1. Return |report|.

Issue: Go through and be consistent about namespacing of algorithms.

To <dfn algorithm for="PrivateAggregation">obtain a report delivery time</dfn>
given a [=moment=] |currentTime|, perform the following steps. They return a
[=moment=].
1. Let |r| be a random double between 0 (inclusive) and 1 (exclusive) with
    uniform probability.
1. Return |currentTime| + [=minimum report delay=] + |r| * [=randomized report
    delay=].

Sending reports {#sending-reports}
----------------------------------

Note: This section is largely copied from the
    <a href="https://wicg.github.io/attribution-reporting-api/">Attribution
    Reporting API spec</a>, adapting as necessary.

Issue: Add logic for resetting [=aggregatable report/queued=] on start up or
    network on or whatever

Issue: Do we have to use the [=queue a task=] algorithm here?

The user agent must periodically [=attempt to queue reports for sending=] with
its [=aggregatable report cache=].

To <dfn>attempt to queue reports for sending</dfn> given a [=list=] of
[=aggregatable reports=] |reports|:
1. [=list/iterate|For each=] |report| of |reports|, run these steps [=in
    parallel=]:
    1. Run these steps, but [=abort when=] the [=user agent=] shuts down:
        1. If |report|'s [=aggregatable report/queued=] value is true, return.
        1. Set |report|'s [=aggregatable report/queued=] value to true.
        1. Let |currentWallTime| be the [=current wall time=].
        1. If |report|'s [=aggregatable report/report time=] is before
            |currentWallTime|, set |report|'s [=aggregatable report/report
            time=] to |currentWallTime| plus an [=implementation-defined=]
            random non-negative [=duration=].

            Note: On startup, it is possible the user agent will need to send
                many reports whose report times passed while the browser was
                closed. Adding random delay prevents temporal joining of
                reports.
        1. Wait until the [=current wall time=] is equal to or after |report|'s
            [=aggregatable report/report time=].
        1. Optionally, wait a further [=implementation-defined=] non-negative
            [=duration=].

            Note: This is intended to allow user agents to optimize device
                resource usage.
        1. Run [=attempt to deliver a report=] with |report|.
    1. [=If aborted=], set |report|'s [=aggregatable report/queued=] value to
        false.

        Note: It might be more practical to perform these steps when the [=user
            agent=] next starts up.

To <dfn>attempt to deliver a report</dfn> given an [=aggregatable report=]
|report|:
1. Let |url| be the result of [=obtaining a reporting endpoint=] given
    |report|'s [=aggregatable report/reporting origin=] and |report|'s
    [=aggregatable report/api=].
1. Let |data| be the result of [=serializing an aggregatable report=] given
    |report|.
1. If |data| is an error, [=list/remove=] |report| from the [=aggregatable
    report cache=]. (TODO: do we need to queue this task?)
1. Let |request| be the result of [=creating a report request=] given |url| and
    |data|.
1. [=Queue a task=] to [=fetch=] |request| with [=fetch/processResponse=] being
    the following steps:
    1. Let |shouldRetry| be an [=implementation-defined=] [=boolean=]. The value
        should be false if no error occurred.
    1. If |shouldRetry| is true, set |report|'s [=aggregatable report/queued=]
        value to false.
    1. Otherwise, [=list/remove=] |report| from the [=aggregatable report
        cache=].

To <dfn>obtain a reporting endpoint</dfn> given an [=origin=] |reportingOrigin|
and [=context type=] |api|, perform the following steps. They return a [=URL=].
1. [=Assert=]: |reportingOrigin| is a [=potentially trustworthy origin=].
1. Let |path| be the [=string/concatenation=] of
    Â«"<code>.well-known/private-aggregation/report-</code>", |api|Â».
1. Let |base| be the result on running the [=URL parser=] on the [=serialization
    of an origin|serialization=] of |reportingOrigin|.
1. [=Assert=]: |base| is not failure.
1. Let |result| be the result of running the [=URL parser=] on |path| with
    |base|.
1. [=Assert=]: |result| is not failure.
1. Return |result|.

To <dfn>create a report request</dfn> given a [=URL=] |url| and a [=byte
sequence=] |body|:
1. Let |request| be a new [=request=] with the following properties:
    :   [=request/method=]
    ::  "`POST`"
    :   [=request/URL=]
    ::  |url|
    :   [=request/header list=]
    ::  Â«("`Content-Type`", "`application/json`")Â»
    :   [=request/unsafe-request flag=]
    ::  set
    :   [=request/body=]
    ::  |body|
    :   [=request/client=]
    ::  `null`
    :   [=request/window=]
    ::  "`no-window`"
    :   [=request/service-workers mode=]
    ::  "`none`"
    :   [=request/initiator=]
    ::  ""
    :   [=request/referrer=]
    :: "`no-referrer`"
    :   [=request/mode=]
    ::  "`cors`"
    :   [=request/credentials mode=]
    ::  "`omit`"
    :   [=request/cache mode=]
    ::  "`no-store`"
1. Return |request|.

Serializing reports {#serializing-reports}
------------------------------------------

Note: This section is largely copied from the
    <a href="https://wicg.github.io/attribution-reporting-api/">Attribution
    Reporting API spec</a>, adapting as necessary.

To <dfn>serialize an aggregatable report</dfn> given an [=aggregatable report=]
|report|, perform the following steps. They return a [=byte sequence=] or an
error.
1. Let |aggregationServicePayloads| be the result of [=obtaining the aggregation
    service payloads=] given |report|.
1. If |aggregationServicePayloads| is an error, return
    |aggregationServicePayloads|.
1. Let |data| be an [=ordered map=] of the following key/value pairs:
    : "`aggregation_service_payloads`"
    :: |aggregationServicePayloads|
    : "`shared_info`"
    :: The result of [=obtaining a report's shared info=] given |report|.
1. Return the [=byte sequence=] resulting from executing [=serialize an infra
    value to JSON bytes=] on |data|.

To <dfn>obtain the aggregation service payloads</dfn> given an [=aggregatable
report=] |report|, perform the following steps. They return a [=list=] of
[=maps=] or an error.
1. Let (|pkR|, |keyId|) be the result of [=obtaining the public key for
    encryption=].
1. If |pkR| is an error, return |pkR|.
1. Let |encryptedPayload| be the result of [=obtaining the encrypted payload=]
    given |report| and |pkR|.
1. If |encryptedPayload| is an error, return |encryptedPayload|.
1. Let |aggregationServicePayloads| be a new [=list/is empty|empty=] [=list=].
1. Let |aggregationServicePayload| be an [=ordered map=] of the following
    key/value pairs:
    : "`key_id`"
    :: |keyId|
    : "`payload`"
    :: |encryptedPayload|, [=forgiving-base64 encode|base64 encoded=]
1. [=list/Append=] |aggregationServicePayload| to |aggregationServicePayloads|.
1. Return |aggregationServicePayloads|.

To <dfn>obtain the public key for encryption</dfn>, asynchronously perform an
[=implementation-defined=] sequence of steps. They return a [=tuple=] consisting
of a public key and a [=string=] (which should uniquely identify the public
key), or an error in the event that the [=user agent=] failed to obtain the
public key. (TODO: why asynchronously.)

Note: The user agent might enforce regular key rotation. If there are multiple
    keys, the user agent might independently pick a key uniformly at random for
    every encryption operation.

To <dfn>obtain the encrypted payload</dfn> given an [=aggregatable report=]
|report|, perform the following steps. They return a [=byte sequence=] or an
error.
1. Let |plaintext| be the result of [=obtaining the plaintext payload=] given
    |report|.
1. Let |sharedInfo| be the result of [=obtaining a report's shared info=] given
    |report|.
1. Let |info| be the result of [=UTF-8 encoding=] the [=string/concatenation=]
    of Â«"`aggregation_service`", |sharedInfo|Â».
1. Let (|kem_id|, |kdf_id|, |aead_id|) be (0x0020, 0x0001, 0x0003).

    Note: These indicate the HPKE algorithm identifiers, specifying the KEM
        function as DHKEM(X25519, HKDF-SHA256), the KDF function as HKDF-SHA256
        and the AEAD function as ChaCha20Poly1305.
1. Let |hpkeContext| be the result of setting up an [[RFC9180|HPKE]]
    [[RFC9180#name-encryption-to-a-public-key|sender's context]] with |pkR|,
    |info|, |kem_id|, |kdf_id| and |aead_id|.
1. Let |aad| be \`\` (an empty [=byte sequence=]).
1. Let |encryptedPayload| be the result of
    [[RFC9180#name-encryption-and-decryption|encrypting]] |plaintext| with
    |hpkeContext| and |aad|.

To <dfn>obtain the plaintext payload</dfn> given an [=aggregatable report=]
    |report|, perform the following steps. They return a [=byte sequence=].
1. Let |payloadData| be a new [=list/is empty|empty=] [=list=].
1. [=list/iterate|For each=] |contribution| of |report|'s [=aggregatable report/
    contributions=]:
    1. Let |contributionData| be an [=ordered map=] of the following key/value
        pairs:
        : "`bucket`"
        :: The result of [=encoding an integer for the payload=] given
            |contribution|["{{PAHistogramContribution/bucket}}"] and 128.
        : "`value`"
        :: The result of [=encoding an integer for the payload=] given
            |contribution|["{{PAHistogramContribution/value}}"] and 32.
    1. [=list/Append=] |contributionData| to |payloadData|.
1. Let |payload| be an [=ordered map=] of the following key/value pairs:
    : "`data`"
    :: |payloadData|
    : "`operation`"
    :: "`histogram`"
1. Return the [=byte sequence=] resulting from [[!RFC8949|CBOR encoding]]
    |payload|.

To <dfn>encode an integer for the payload</dfn> given an integer |intToEncode|
and an integer |bitLength|, return the representation of |intToEncode| as a
big-endian [=byte sequence=] of length |bitLength| / 8, left padding with zeroes
as necessary.

To <dfn>obtain a report's shared info</dfn> given an [=aggregatable report=]
|report|, perform the following steps. They return a [=string=].
1. Let |scheduledReportTime| be the [=duration from=] the [=UNIX epoch=] to
    |report|'s [=aggregatable report/original report time=].
1. Let |sharedInfo| be an [=ordered map=] of the following key/value pairs:
    : "`api`"
    :: |report|'s [=aggregatable report/api=]
    : "`report_id`"
    :: |report|'s [=aggregatable report/report ID=]
    : "`reporting_origin`"
    :: The [=serialization of an origin|serialization=] of |report|'s
        [=aggregatable report/reporting origin=]
    : "`scheduled_report_time`"
    :: The number of seconds in |scheduledReportTime|, rounded down to the
        nearest number of whole seconds and [=serialize an integer|serialized=]
    : "`version`"
    :: "`0.1`"
1. Return the result of [=serializing an infra value to a json string=] given
    |sharedInfo|.


Protected Audience API-specific {#protected-audience-api-specific-algorithms}
-----------------------------------------------------------------------------

To <dfn>fill in the contribution</dfn> given a |contribution|, perform the
following steps. They return a {{PAHistogramContribution}}.
1. If |contribution| is a {{PAHistogramContribution}}, return |contribution|.
1. Otherwise, [=assert=]: |contribution| is a
    {{PAExtendedHistogramContribution}}.
1. Let |bucket| be |contribution|["{{PAExtendedHistogramContribution/bucket}}"].
1. If |bucket| is a {{PASignalValue}}, set |bucket| to the result of [=filling
    in the signal value=] given |bucket| and 65535.
1. Let |value| be |contribution|["{{PAExtendedHistogramContribution/value}}"].
1. If |value| is a {{PASignalValue}}, set |value| to the result of [=filling in
    the signal value=] given |value| and 2<sup>128</sup>âˆ’1.
1. Return a new {{PAHistogramContribution}} with the items:
    : {{PAHistogramContribution/bucket}}
    :: |bucket|
    : {{PAHistogramContribution/value}}
    :: |value|

To <dfn>fill in the signal value</dfn> given a {{PASignalValue}} |value| and an
integer |maxAllowed|, perform the following steps. They return an integer.
1. [=Assert=]: |value|["{{PASignalValue/baseValue}}"] is a valid [=signal base
    value=].
1. Let |returnValue| be the result of [=determining the numeric value=] of
    |value|["{{PASignalValue/baseValue}}"].
1. If |value|["{{PASignalValue/scale}}"] [=map/exists=], set |returnValue| to
    the result of multiplying |value|["{{PASignalValue/scale}}"] with
    |returnValue|.
1. Set |returnValue| to the integer result of rounding |returnValue| to the
    nearest integer. If two integers are equally close, the result should be the
    integer closer to negative infinity.
1. If |value|["{{PASignalValue/offset}}"] [=map/exists=], set |returnValue| to
    the result of adding |returnValue| to |value|["{{PASignalValue/offset}}"].
1. Clamp |returnValue| to the range [0, |maxAllowed|] and return the result.

Issue: Maybe add refs to the rounding logic.

To <dfn>determine the numeric value</dfn> of a [=signal base value=]
<var ignore=''>signalBaseValue</var>, perform the following steps. They return a
{{double}}.

Issue: Fill in.
