<pre class='metadata'>
Title: Private Aggregation API
Shortname: private-aggregation-api
Level: 1
Status: w3c/CG-DRAFT
Group: patcg
Repository: patcg-individual-drafts/private-aggregation-api
URL: https://patcg-individual-drafts.github.io/private-aggregation-api
Editor: Alexander Turner, Google https://www.google.com, alexmt@chromium.org
Abstract: A generic API for measuring aggregate, cross-site data in a privacy preserving manner. The potentially identifying cross-site data is encapsulated into <em>aggregatable reports</em>. To prevent leakage, this data is encrypted, ensuring it can only be processed by an <em>aggregation service</em>. During processing, this service will add noise and impose limits on how many queries can be performed.

<!--- Warning: Not Ready -->
Markup Shorthands: markdown on
Complain About: accidental-2119 on, missing-example-ids on
Assume Explicit For: on
</pre>

<pre class="anchors">
urlPrefix: https://wicg.github.io/turtledove/; type: interface
    text: FledgeWorkletGlobalScope
urlPrefix: https://wicg.github.io/shared-storage/; type: interface
    text: SharedStorageWorkletGlobalScope
spec: hr-time; type: dfn; urlPrefix: https://w3c.github.io/hr-time/
    text: moment; url: #dfn-moment
</pre>

Introduction {#intro}
=====================

<em>This section is non-normative.</em>

Motivation {#motivation}
------------------------

Browsers are now working to prevent cross-site user tracking, including by
partitioning storage and removing third-party cookies. There are a range of API
proposals to continue supporting legitimate use cases in a way that respects
user privacy. Many of these APIs, including <a href="https://wicg.github.io/shared-storage/">Shared Storage</a> and <a href="https://wicg.github.io/turtledove/">FLEDGE</a>, isolate
potentially identifying cross-site data in special contexts, which ensures that
the data cannot escape the user agent.

Relative to cross-site data from an individual user, aggregate data about groups
of users can be less sensitive and yet would be sufficient for a wide range of
use cases. An aggregation service has been proposed to allow reporting noisy,
aggregated cross-site data. This service was originally proposed for use by the
Attribution Reporting API, but allowing more general aggregation would support
additional use cases. In particular, the FLEDGE and Shared Storage proposals
expect this functionality to become available.

Overview {#overview}
--------------------

This document oulines a general-purpose API that can be called from isolated
contexts that have access to cross-site data (such as a Shared Storage worklet).
Within these contexts, potentially identifying data can be encapsulated into
"aggregatable reports". To prevent leakage, the cross-site data in these reports
is encrypted to ensure it can only be processed by the aggregation service.
During processing, this service adds noise and imposes limits on how many
queries can be performed.

This API provides functions allowing the origin to construct an aggregatable
report and specify the values to be embedded into its encrypted payload (for
later computation via the aggregation service). These calls result in the
aggregatable report being queued to be sent to the reporting endpoint of the
script's origin after a delay. After the endpoint receives the reports, it will
batch the reports and send them to the aggregation service for processing. The
output of that process is a summary report containing the (approximate) result,
which is dispatched back to the script's origin.

General methods {#general-methods}
==================================

Worklet interface {#worklet-interface}
--------------------------------------

<xmp class="idl">
[Exposed=(FledgeWorkletGlobalScope,SharedStorageWorkletGlobalScope)]
interface PrivateAggregation {
  undefined sendHistogramReport(PAHistogramContribution contribution);
};

[Exposed=(FledgeWorkletGlobalScope,SharedStorageWorkletGlobalScope)]
dictionary PAHistogramContribution {
  required bigint bucket;
  required long value;
};
</xmp>

Each {{PrivateAggregation}} has a <dfn>contributions cache</dfn>, a [=list=].

Note: The steps to process the [=contributions cache=] are defined separately for
each {{WorkletGlobalScope}}.

Issue: Do we need to spec enableDebugMode?

Issue: Need to spec Permissions Policy integration.

<div algorithm>
The <dfn method for="PrivateAggregation">sendHistogramReport(PAHistogramContribution contribution)</dfn> method steps are:
</div>

1. Throw error if |contribution|'s {{PAHistogramContribution/value}} is negative.
1. Throw error if |contribution|'s {{PAHistogramContribution/bucket}} is not in the range [0, 2<sup>128</sup>−1].
1. [=list/Append=] |contribution| to the [=contributions cache=].

Issue: Check that value can actually be zero in the spec pipeline.

Issue: Properly throw an error here.


Exposing to Shared Storage {#shared-storage}
============================================

<xmp class="idl">
partial interface SharedStorageWorkletGlobalScope {
  readonly attribute PrivateAggregation privateAggregation;
};
</xmp>

Immediately after an operation completes, [=process the Shared Storage contributions cache=] with the worklet's [=contributions cache=] and the worklet's global scope.

Issue: How to handle batching different operation invocations properly. This doesn't work for simultaneous operations.

To <dfn>process the Shared Storage contributions cache</dfn> given a [=contributions cache=] |contributionsCache| and a {{SharedStorageWorkletGlobalScope}} |scope|, run the [=PrivateAggregation/report scheduling steps=] with |scope|'s [=relevant settings object=]'s [=origin=], "<code>[=worklet type identifier/shared-storage=]</code>" and |contributionsCache|.

Exposing to FLEDGE {#fledge}
============================

<xmp class="idl">
partial interface FledgeWorkletGlobalScope {
  readonly attribute PrivateAggregation privateAggregation;
};

[Exposed=FledgeWorkletGlobalScope]
dictionary PASignalValue {
  required DOMString baseValue;
  double scale;
  (bigint or long) offset;
};

[Exposed=FledgeWorkletGlobalScope]
dictionary PAExtendedHistogramContribution {
  required (PASignalValue or bigint) bucket;
  required (PASignalValue or long) value;
};

[Exposed=FledgeWorkletGlobalScope]
partial interface PrivateAggregation {
  undefined reportContributionForEvent(DOMString event, PAExtendedHistogramContribution contribution);
};
</xmp>

Issue: Do we want to align naming with implementation?

Immediately after an auction completes, [=process the FLEDGE contributions cache=] with the worklet's [=contributions cache=] and the worklet's global scope.

Issue: Does FLEDGE have one global scope per auction or multiple? If multiple, will need to change scope.

Issue: How to handle fenced frame-triggered contributions and other event-triggered contributions.

<div algorithm>
The <dfn method for="PrivateAggregation">reportContributionForEvent(DOMString event, PAExtendedHistogramContribution contribution)</dfn> method steps are:
</div>

1. Run the [=PrivateAggregation/validate an extended histogram contribution=] steps on |contribution|.

Issue: Fill in the rest. (Need to put the contribution in some sort of queue and process the queue at some point. Need to decide where the queue should live given it has to outlive the auction.)

To <dfn>process the FLEDGE contributions cache</dfn> given a [=contributions cache=] |contributionsCache| and a {{FledgeWorkletGlobalScope}} |scope|, run the following steps:
1. Let |filledInContributions| be a new [=list/is empty|empty=] [=list=].
1. [=list/iterate|For each=] |contribution| of |contributionsCache|:
    1. [=list/Append=] the result of [=filling in the contribution=] with |contribution| to |filledInContributions|.
1. Run the [=PrivateAggregation/report scheduling steps=] with |scope|'s [=relevant settings object=]'s [=origin=], "<code>[=worklet type identifier/fledge=]</code>" and |filledInContributions|.


Structures {#structures}
========================

<h3 dfn-type=dfn>Aggregatable report</h3>

An aggregatable report is a [=struct=] with the following items:
<dl dfn-for="aggregatable report">
: <dfn>reporting origin</dfn>
:: An [=origin=]
: <dfn>original report time</dfn>
:: A [=moment=]
: <dfn>report time</dfn>
:: A [=moment=]
: <dfn>contributions</dfn>
:: A [=list=] of {{PAHistogramContribution}}s
: <dfn>api</dfn>
:: A [=worklet type identifier=]
: <dfn>report ID</dfn>
:: A [=string=]

</dl>

Issue: Handle operation types, aggregation coordinators, maybe retries/offline, report verification

<h3 dfn-type=dfn>Worklet type identifier</h3>
A worklet type identifier is one of the following:
<dl dfn-for="worklet type identifier">
: "<dfn><code>fledge</code></dfn>"
:: The global scope was a {{FledgeWorkletGlobalScope}}.
: "<dfn><code>shared-storage</code></dfn>"
:: The global scope was a {{SharedStorageWorkletGlobalScope}}.

</dl>

Issue: Consider renaming worklet type identifier.

<h3 dfn-type=dfn>Signal base value</h3>
A signal base value is one of the following:
<dl dfn-for="signal base value">
: "<dfn export><code>winning-bid</code></dfn>"
:: The bid value of the winning bid.
: "<dfn export><code>highest-scoring-other-bid</code></dfn>"
:: The bid value of the highest scoring bid that did not win.
: "<dfn export><code>script-run-time</code></dfn>"
:: The running time of the script in ms(?).
: "<dfn export><code>signals-fetch-time</code></dfn>"
:: The time it took for the signals fetch to complete in ms(?)
: "<dfn export><code>bid-reject-reason</code></dfn>"
:: The reason a bid was rejected.

</dl>

Issue: Remove exports when these definitions are used.

Issue: Make sure these definitions match "determine the numeric value" algorithm

Issue: New enum needed for bid reject reasons.

Storage {#storage}
==================

A user agent holds an <dfn>aggregatable report cache</dfn>, which is a [=list=] of [=aggregatable reports=].

Vendor-specific values {#vendor-specific-values}
================================================

Issue: Should we use the term "implementation-defined" instead?

<dfn>Max stored reports</dfn> is a positive integer that controls how many unsent reports can be queued waiting.

<dfn>Max report contributions</dfn> is a positive integer that controls how many contributions can be present in a single report.

Issue: More

Algorithms {#algorithms}
====================


<!-- A {{WorkletGlobalScope}} |scope|'s <dfn algorithm for="PrivateAggregation">api identifier</dfn> is the result of:
1. If |scope|'s [=worklet global scope type=] is {{FledgeWorkletGlobalScope}}, then return "<code>[=worklet type identifier/fledge=]</code>".
1. [=Assert=]: |scope|'s [=worklet global scope type=] is {{SharedStorageWorkletGlobalScope}}.
1. Return "<code>[=worklet type identifier/shared-storage=]</code>". -->

To <dfn export algorithm for="PrivateAggregation">obtain a reporting endpoint</dfn> given an [=origin=] |reportingOrigin| and [=worklet type identifier=] |api|:
1. [=Assert=]: |reportingOrigin| is a [=potentially trustworthy origin=].
1. Let |path| be the [=string/concatenation=] of «"<code>.well-known/private-aggregation/report-</code>", |api|».
1. Let |base| be the result on running the [=URL parser=] on the [=serialization of an origin|serialization=] of |reportingOrigin|.
1. Return the result of running the [=URL parser=] on |path| with |base|.

Issue: Remove export when this definition is used.

To <dfn for="PrivateAggregation">obtain an aggregatable report</dfn> given an [=origin=] |reportingOrigin|, a [=worklet type identifier=] |api| and a [=list=] of {{PAHistogramContribution}} |contributions|:
1. [=Assert=]: |reportingOrigin| is a [=potentially trustworthy origin=].
1. Let |reportTime| be the result of running [=PrivateAggregation/obtain a report delivery time=].
1. Let |report| be a new [=aggregatable report=] with the items:
    : [=aggregatable report/reporting origin=]
    :: |reportingOrigin|
    : [=aggregatable report/original report time=]
    :: |reportTime|
    : [=aggregatable report/report time=]
    :: |reportTime|
    : [=aggregatable report/contributions=]
    :: |contributions|
    : [=aggregatable report/api=]
    :: |api|
    : [=aggregatable report/report ID=]
    :: The result of [=generating a random UUID=].

Scheduling reports {#scheduling-reports}
----------------------------------------

To <dfn algorithm for="PrivateAggregation">obtain a report delivery time</dfn>, run the following steps:

Issue: Fill in

The <dfn algorithm for="PrivateAggregation">report scheduling steps</dfn> given an [=origin=] |reportingOrigin|, a [=worklet type identifier=] |api| and a [=list=] of {{PAHistogramContribution}} |contributions| are as follows:
1. [=Assert=]: |reportingOrigin| is a [=potentially trustworthy origin=].
1. Let |truncatedContributions| be a new [=list/is empty|empty=] [=list=].
1. If |contributions| has a [=list/size=] greater than [=max report contributions=]:
    1. [=set/For each=] |n| of [=the range=] 0 to [=max report contributions=], exclusive:
        1. [=set/Append=] |contributions|[|n|] to |truncatedContributions|.
1. Otherwise, set |truncatedContributions| to |contributions|.
1. Let |contributionSum| be 0.
1. [=set/iterate|For each=] |contribution| of |truncatedContributions|:
    <!-- 1. [=Assert=]: |contribution| is a {{PAHistogramContribution}}. -->
    1. [=Assert=]: |contribution|'s |value| is non-negative.
    1. Add |value| to |contributionSum|.
1. Let |sufficientBudget| be the result of running [=PrivateAggregation/consume budget if permitted=] on |contributionSum|, |reportingOrigin| and |api|.
1. If not |sufficientBudget|, return.
1. Let |report| be the result of [=PrivateAggregation/obtaining an aggregatable report=] given |reportingOrigin|, |api| and |truncatedContributions|.
1. If the user agent's [=aggregatable report cache=] [=set/size=] is larger than [=max stored reports=], return.
1. [=set/Append=] |report| to the user agent's [=aggregatable report cache=].

Issue: Do we need to ensure the reports aren't queued after being sent?

Issue: non-negative or positive value?

Issue: Do we need to address user settings here at all?

Issue: Batching

Issue: Does the [=max stored reports=] part match the implementation?

To <dfn algorithm for="PrivateAggregation">consume budget if permitted</dfn> given a {{long}} |value|, an [=origin=] <var ignore=''>origin</var> and an [=worklet type identifier=] |api| are a user agent-determined sequence of steps that returns a {{boolean}} indicating whether there is a sufficient 'contribution budget' left to send the requested contribution |value|. This budget should be bound to usage over time, e.g. the contribution sum over the last 24 hours. The algorithm should assume that the contribution will be sent if true is returned (and won't otherwise).

Issue: Do we want to specify how budgeting works? ARA does, but leaves the exact values up to the implementer.

<!-- Example algo:
1. Maintain a store somewhere of all previous reports or like the last 24 h or something
1. Let |budget_already_used| be 0.
1. For each entry in this store:
    1. If time is more than 24 hours ago, delete it.
    1. (Optionally, if the time is old enough, delete it.)
        - We could make this just a general, if the time is earlier than the budget scope beginning (which is a user agent-determined time and a function of "now"). That feels a bit too tied to the implementation...
    1. If different |origin| or different |api|, continue.
    1. Increment |budget_already_used| by this entry's |value|.
1. Set |is_allowed| to a boolean indicating whether |budget_already_used| + the requested contribution is less than or equal to the maximum daily allowed budget.
1. If |is_allowed|
    1. Add entry to the store
1. Return |is_allowed|.

So we could do this and then specify that implementers should use an algo with similar results to this? Or we could say the user agent may reject additional reports for algorithmic simplicity or something. -->

Issue: Don't we need to take into account the time "now" as well?

Sending reports {#sending-reports}
----------------------------------

Issue: Fill in. Compare to Report delivery in ARA spec. Include a section on serializing reports.

FLEDGE-specific algorithms {#fledge-specific-algorithms}
--------------------------------------------------------


To <dfn>fill in the contribution</dfn> given a |contribution|, run the following steps:
1. If |contribution| is a {{PAHistogramContribution}}, return |contribution|.
1. Otherwise, [=assert=] |contribution| is a {{PAExtendedHistogramContribution}}.
1. Let |bucket| be |contribution|'s {{PAExtendedHistogramContribution/bucket}}.
1. If |bucket| is a {{PASignalValue}}, let |bucket| be the result of [=filling in the signal value=] given |bucket| and 65535.
1. Let |value| be |contribution|'s {{PAExtendedHistogramContribution/value}}.
1. If |value| is a {{PASignalValue}}, let |value| be the result of [=filling in the signal value=] given |value| and 2<sup>128</sup>−1.
1. Return a new {{PAHistogramContribution}} with the items:
    : {{PAHistogramContribution/bucket}}
    :: |bucket|
    : {{PAHistogramContribution/value}}
    :: |value|

To <dfn>fill in the signal value</dfn> given a {{PASignalValue}} |value| and an integer |maxAllowed|, run the following steps:
1. [=Assert=] |value|'s {{PASignalValue/baseValue}} is a valid [=signal base value=].
1. Let |returnValue| be the result of [=determining the numeric value=] of |value|'s {{PASignalValue/baseValue}}.
1. If |value|'s {{PASignalValue/scale}} is set:
    1. Let |returnValue| be the result of multiplying |value|'s {{PASignalValue/scale}} with |returnValue|.
1. Let |returnValue| be the integer result of rounding |returnValue| to the nearest integer. If two integers are equally close, the result should be the integer closer to negative infinity.
1. If |value|'s {{PASignalValue/offset}} is set:
    1. Let |returnValue| be the result of adding |returnValue| to |value|'s {{PASignalValue/offset}}.
1. Clamp |returnValue| to the range [0, |maxAllowed|] and return the result.

Issue: Maybe add refs to the rounding logic.

To <dfn>determine the numeric value</dfn> of a [=signal base value=] <var ignore=''>signalBaseValue</var>, run the following steps:

Issue: Fill in.

<!-- [Exposed=FledgeWorkletGlobalScope]
dictionary PASignalValue {
  required DOMString baseValue;
  double scale;
  (bigint or long) offset;
}; -->

<!--
To <dfn>process the contributions cache</dfn> given a [=list=] |contributionsCache|, run the [=PrivateAggregation/report scheduling steps=] with the associated {{WorkletGlobalScope}}'s [=relevant settings object=]'s [=origin=], the the associated {{WorkletGlobalScope}}'s [=PrivateAggregation/api identifier=] and |contributionsCache|.

To <dfn>process the contributions cache</dfn> given a {{WorkletGlobalScope}} |scope| and a [=list=] |contributionsCache|, run the [=PrivateAggregation/report scheduling steps=] with |scope|'s [=relevant settings object=]'s [=origin=], the |scope's| [=PrivateAggregation/api identifier=] and the [=contributions cache=].


Immediately after the {{WorkletGlobalScope}} object is [=terminate a worklet global scope|terminated=], run the [=PrivateAggregation/report scheduling steps=] with the {{WorkletGlobalScope}}'s [=relevant settings object=]'s [=origin=], the {{WorkletGlobalScope}} [=PrivateAggregation/api identifier=] and the [=contributions cache=].
 -->



To <dfn algorithm for="PrivateAggregation">validate an extended histogram contribution</dfn> given a {{PAExtendedHistogramContribution}} |contribution|:

Issue: Fill in. Will need to check offsets are valid and in the right range for the type etc. Also that base values are one of a set.

Issue: Need to document limits on offset, etc.
