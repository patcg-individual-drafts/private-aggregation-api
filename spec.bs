<pre class='metadata'>
Title: Private Aggregation API
Shortname: private-aggregation-api
Level: 1
Status: UD
Group: patcg-id
Repository: patcg-individual-drafts/private-aggregation-api
URL: https://patcg-individual-drafts.github.io/private-aggregation-api
Editor: Alexander Turner, Google https://www.google.com, alexmt@chromium.org
Abstract: A generic API for measuring aggregate, cross-site data in a privacy
    preserving manner. The potentially identifying cross-site data is
    encapsulated into <em>aggregatable reports</em>. To prevent leakage, this
    data is encrypted, ensuring it can only be processed by an <em>aggregation
    service</em>. During processing, this service will add noise and impose
    limits on how many queries can be performed.
Markup Shorthands: markdown on
Complain About: accidental-2119 on, missing-example-ids on
Assume Explicit For: on
</pre>

<pre class="anchors">
urlPrefix: https://wicg.github.io/turtledove/; type: interface
    text: InterestGroupBiddingScriptRunnerGlobalScope
    text: InterestGroupScriptRunnerGlobalScope
    text: InterestGroupScoringScriptRunnerGlobalScope
    text: InterestGroupReportingScriptRunnerGlobalScope
urlPrefix: https://wicg.github.io/shared-storage/; type: interface
    text: SharedStorageWorklet
    text: SharedStorageWorkletGlobalScope
spec: hr-time; type: dfn; urlPrefix: https://w3c.github.io/hr-time/
    text: current wall time; url: #dfn-current-wall-time
    text: duration; url: #dfn-duration
    text: duration from; url: #dfn-duration-from
    text: moment; url: #dfn-moment
    text: unix epoch; url: #dfn-unix-epoch
    text: wall clock; url: #dfn-wall-clock
spec: html; type: dfn; urlPrefix: https://tc39.es/ecma262/
    text: call; url: sec-call
spec: webdriver; urlPrefix: https://w3c.github.io/webdriver/
    type: dfn
        text: getting a property; url: dfn-getting-properties
        text: error code; url: dfn-error-code
spec: fenced-frame; urlPrefix: https://wicg.github.io/fenced-frame/
    type: dfn;
        for: browsing context;
            text: fenced frame config instance; url: browsing-context-fenced-frame-config-instance
</pre>

<pre class=link-defaults>
spec:infra; type:dfn; text:user agent
spec:webidl; type:dfn; text:attribute
</pre>


Introduction {#intro}
=====================

<em>This section is non-normative.</em>

Motivation {#motivation}
------------------------

Browsers are now working to prevent cross-site user tracking, including by
partitioning storage and removing third-party cookies. There are a range of API
proposals to continue supporting legitimate use cases in a way that respects
user privacy. Many of these APIs, including the
<a href="https://wicg.github.io/shared-storage/">Shared Storage API</a> and the
<a href="https://wicg.github.io/turtledove/">Protected Audience API</a>, isolate
potentially identifying cross-site data in special contexts, which ensures that
the data cannot escape the user agent.

Relative to cross-site data from an individual user, aggregate data about groups
of users can be less sensitive and yet would be sufficient for a wide range of
use cases. An aggregation service has been built to allow reporting noisy,
aggregated cross-site data. This service was originally created for use by the
<a href="https://wicg.github.io/attribution-reporting-api/">Attribution
Reporting API</a>, but allowing more general aggregation supports additional use
cases. In particular, the Protected Audience and Shared Storage APIs expect this
functionality to be available.

Overview {#overview}
--------------------

This document outlines a general-purpose API that can be called from isolated
contexts that have access to cross-site data (such as a Shared Storage worklet).
Within these contexts, potentially identifying data can be encapsulated into
"aggregatable reports". To prevent leakage, the cross-site data in these reports
is encrypted to ensure it can only be processed by the aggregation service.
During processing, this service adds noise and imposes limits on how many
queries can be performed.

This API provides functions that allow the origin to construct an aggregatable
report and specify the values to be embedded into its encrypted payload (for
later computation via the aggregation service). These calls result in the
aggregatable report being queued to be sent to the reporting endpoint of the
script's origin after a delay. After the endpoint receives the reports, it will
batch the reports and send them to the aggregation service for processing. The
output of that process is a summary report containing the (approximate) result,
which is dispatched back to the script's origin.

Alternative considered {#alternative-considered}
------------------------------------------------

Instead of the chosen API shape, we considered aligning with a design that is
much closer to {{WindowOrWorkerGlobalScope/fetch()}}. However, there are a few
key differences which make this unfavorable:
- This API is designed to be used in isolated contexts where
    {{WindowOrWorkerGlobalScope/fetch()}} is not available.
- It's an anti-goal to give the developer control over when [=aggregatable
    reports=] are being sent or knowledge that they were sent (outside of the
    isolated context). Note, however, the exception when providing a context ID
    from <em>outside</em> the isolated context, see [Protecting against leaks
    via the number of
    reports](#protecting-against-leaks-via-the-number-of-reports) below.
- The reports cannot be sent to arbitrary reporting endpoints, only a
    particular <code>[[RFC8615|.well-known]]</code> path on the script origin.
- The report's input is very specific (an array of {{PAHistogramContribution}}s)
    and is not amenable to {{WindowOrWorkerGlobalScope/fetch()}}'s general
    purpose contents.
- There is no concept of a response.

So, we chose the more tailored API shape detailed below.

Exposed interface {#exposed-interface}
======================================

<xmp class="idl">
[Exposed=(InterestGroupScriptRunnerGlobalScope,SharedStorageWorklet),
 SecureContext]
interface PrivateAggregation {
  undefined contributeToHistogram(PAHistogramContribution contribution);
  undefined contributeToHistogramOnEvent(DOMString event,
                                         record<DOMString, any> contribution);
  undefined reserveNamedBudgets(record<DOMString, double> namedBudgets);
  undefined enableDebugMode(optional PADebugModeOptions options = {});
};

dictionary PAHistogramContribution {
  required bigint bucket;
  required long value;
  bigint filteringId = 0;
  DOMString? namedBudget = null;
};

dictionary PADebugModeOptions {
  required bigint debugKey;
};
</xmp>

Issue: Per the <a href=https://www.w3.org/TR/design-principles/#numeric-types>
  Web Platform Design Principles</a>, we should consider switching `long` to
  `[EnforceRange] long long`.

Issue: {{PrivateAggregation/enableDebugMode(options)}}'s argument should not
    have a default value of `{}`. Alternatively, {{PADebugModeOptions/debugKey}}
    should not be required in {{PADebugModeOptions}}.

Each {{PrivateAggregation}} object has the following fields:
<dl dfn-for="PrivateAggregation">
: <dfn export>scoping details</dfn> (default null)
:: A [=scoping details=] or null
: <dfn export>allowed to use</dfn> (default false)
:: A [=boolean=]
: <dfn export>should perform default contributeToHistogramOnEvent()
    processing</dfn> (default an algorithm that always returns true)
:: An algorithm that takes a {{PrivateAggregation}}, {{DOMString}} and a [=map=]
    (with {{DOMString}} keys) and returns either a [=boolean=] or an
    [=exception=].

    Note: This allows embedding APIs to override processing for all calls or
        just certain ones. A return value of true indicates that this call will
        be processed using the default implementation in this spec. A return
        value that is an [=exception=] allows the embedding API's processing to
        [=exception/throw=].

</dl>

Note: See [Exposing to global scopes](#exposing) below.

<div algorithm>
The <dfn method for="PrivateAggregation">
contributeToHistogram(PAHistogramContribution |contribution|)</dfn> method steps
are:

1. Let |scopingDetails| be [=this=]'s [=PrivateAggregation/scoping details=].
1. Let |namedBudgetExists| be the result of [=checking that a contribution's
    named budget exists=] given |contribution| and |scopingDetails|.
1. If |namedBudgetExists| is false, [=exception/throw=] a "{{DataError}}"
    {{DOMException}}.
1. Let |validationResult| be the result of [=validating a histogram
    contribution=] given |contribution| and |scopingDetails|.
1. If |validationResult| is an [=exception=], [=exception/throw=]
    |validationResult|.
1. [=Assert=]: |validationResult| is a [=contribution cache entry=].
1. [=Append an entry to the contribution cache|Append=] |validationResult| to
    the [=contribution cache=].

Issue(44): Consider accepting an array of contributions.

</div>

<div algorithm>
The <dfn method for="PrivateAggregation">contributeToHistogramOnEvent(|event|,
|contribution|)</dfn> method steps are:

1. Let |scopingDetails| be [=this=]'s [=PrivateAggregation/scoping details=].
1. Let |namedBudgetExists| be the result of [=checking that a contribution's
    named budget exists=] given |contribution| and |scopingDetails|.
1. If |namedBudgetExists| is false, [=exception/throw=] a "{{DataError}}"
    {{DOMException}}.
1. Let |defaultProcessingResult| be the result of running [=this=]'s
    [=PrivateAggregation/should perform default contributeToHistogramOnEvent()
    processing=] given [=this=], |event| and |contribution|.
1. If |defaultProcessingResult| is an [=exception=], [=exception/throw=]
    |defaultProcessingResult|.
1. If |defaultProcessingResult| is false, return.
1. Set |contribution| to the result of [=converted to an IDL value|converting=]
    |contribution|'s [=converted to a JavaScript value|JavaScript value=] to the
    IDL type {{PAHistogramContribution}}.

    Note: This throws a {{TypeError}} if |contribution| is not compatible.
1. Let |validationResult| be the result of [=validating a histogram
    contribution=] given |contribution| and |scopingDetails|.
1. If |validationResult| is an [=exception=], [=exception/throw=]
    |validationResult|.
1. [=Assert=]: |validationResult| is a [=contribution cache entry=].
1. If |event| does not [=string/start with=] "<code>reserved.</code>",
    [=exception/throw=] a {{TypeError}}.
1. Let |unprefixedEvent| be the [=code unit substring=] from
    "<code>reserved.</code>"'s [=string/length=] to |event|'s [=string/length=]
    within |event|.
1. If |unprefixedEvent| [=string/is=] any of the [=internal error events=]:
    1. Let |maybeContributionCacheEntry|'s [=contribution cache entry/error
        event=] be |unprefixedEvent|.
    1. [=Append an entry to the contribution cache|Append=]
        |maybeContributionCacheEntry| to the [=contribution cache=].

Note: For forward compatibility, we do not throw an error for unrecognized
    events that [=string/start with=] "<code>reserved.</code>".

</div>

<div algorithm>
The <dfn method
for="PrivateAggregation">reserveNamedBudgets(record&lt;DOMString, double&gt;
|namedBudgets|)</dfn> method steps are:

1. Let |scopingDetails| be [=this=]'s [=PrivateAggregation/scoping details=].
1. Let |batchingScope| be the result of running |scopingDetails|' [=scoping
    details/get batching scope steps=].
1. If [=named budget ledgers map=][|batchingScope|] [=map/exists=],
    [=exception/throw=] a "{{DataError}}" {{DOMException}}.

    Note: Repeat calls are rejected once a set of named budgets has been
    accepted.
1. If |namedBudgets| [=map/is empty=], [=exception/throw=] a "{{DataError}}"
    {{DOMException}}.
1. If |namedBudgets|' [=map/size=] is greater than [=maximum number of named
    budgets=], [=exception/throw=] a "{{DataError}}" {{DOMException}}.
1. [=map/For each=] |name| → |fraction| of |namedBudgets|:
    1. If |name|'s [=string/length=] is greater than [=maximum length of budget
        name=], [=exception/throw=] a "{{DataError}}" {{DOMException}}.

        Note: The empty string is treated the same as any other budget name.
        It is distinct from null, which is used to represent the default budget.
    1. If |fraction| is negative or greater than 1, [=exception/throw=] a
        "{{DataError}}" {{DOMException}}.

        Note: The value of |fraction| is guaranteed to be finite by the
        definition of {{double}}.
1. Let |ledgers| be a new [=list=] of [=named budget ledgers=].
1. [=list/iterate|For each=] |budgetingScope| in [=all budgeting scopes=]:
    1. Let |maxBudget| be |budgetingScope|'s [=budgeting scope/max budget=].
    1. Let |maxBudgetDouble| be a {{double}} value equal to |maxBudget|.
    1. Let |remainingBudget| be |maxBudget|.
    1. Let |ledger| be a new [=named budget ledger=].
    1. [=map/For each=] |name| → |fraction| of |namedBudgets|:
        1. Let |allocationDouble| be the value of |fraction| multiplied by
            |maxBudgetDouble|.
        1. Let |allocation| be an integer equal to the floor of
            |allocationDouble|.
        1. If |allocation| is not contained in [=the inclusive range|the range=]
            from 0 to |maxBudget|, inclusive, [=exception/throw=] a
            "{{DataError}}" {{DOMException}}.
        1. If |allocation| is greater than |remainingBudget|,
            [=exception/throw=] a "{{DataError}}" {{DOMException}}.
        1. Set |remainingBudget| to |remainingBudget| - |allocation|.
        1. [=map/Set=] |ledger|[|name|] to |allocation|.
    1. [=map/Set=] |ledger|[null] to |remainingBudget|.

        Issue: Consider throwing an exception when the default budget is
        implicitly zero.
    1. [=list/Append=] |ledger| to |ledgers|.
1. [=map/Set=] [=named budget ledgers map=][|batchingScope|] to |ledgers|.

Issue: Review the types of all exceptions used above.

</div>

<div algorithm>
The <dfn method for="PrivateAggregation">
enableDebugMode(optional PADebugModeOptions options)</dfn> method steps are:

1. Let |scopingDetails| be [=this=]'s [=PrivateAggregation/scoping details=].
1. Let |debugScope| be the result of running |scopingDetails|' [=scoping
    details/get debug scope steps=].
1. If [=debug scope map=][|debugScope|] [=map/exists=], [=exception/throw=] a
    "{{DataError}}" {{DOMException}}.

    Note: This would occur if `enableDebugMode()` has already been run for this
        [=debug scope=].
1. Let |debugKey| be null.
1. If |options| was given:
    1. If |options|["{{PADebugModeOptions/debugKey}}"] is not [=set/contained=]
        in [=the exclusive range|the range=] 0 to 2<sup>64</sup>, exclusive,
        [=exception/throw=] a "{{DataError}}" {{DOMException}}.
    1. Set |debugKey| to |options|["{{PADebugModeOptions/debugKey}}"].
1. Let |debugDetails| be a new [=debug details=] with the items:
    : [=debug details/enabled=]
    :: true
    : [=debug details/key=]
    :: |debugKey|

1. Optionally, set |debugDetails| to a new [=debug details=].

    Note: This allows the user agent to make debug mode unavailable globally or
        just for certain callers.
1. [=map/Set=] [=debug scope map=][|debugScope|] to |debugDetails|.

Issue: Ensure errors are of an appropriate type, e.g. {{InvalidAccessError}} is
    deprecated.
</div>

Exposing to global scopes {#exposing}
=====================================

To expose this API to a global scope, a [=read only=] [=attribute=]
`privateAggregation` of type {{PrivateAggregation}} should be exposed on the
global scope. Its [=getter steps=] should be set to the [=get the
privateAggregation=] steps given [=this=].

Each global scope should set the [=PrivateAggregation/allowed to use=] for the
{{PrivateAggregation}} object it exposes based on whether a relevant
[=document=] is [=allowed to use=] the "<code>[=private-aggregation=]</code>"
[=policy-controlled feature=].

Additionally, each global scope should set the [=PrivateAggregation/scoping
details=] for the {{PrivateAggregation}} object it exposes to a non-null value.
The global scope should wait to set the field until the API is intended to be
available.

<div class="example" id="shared-storage-only-within-operations">
    Shared Storage only allows Private Aggregation when an operation is being
    invoked, not in the top-level context:
    <pre highlight="js">
    class ExampleOperation {
      async run(data) {
        privateAggregation.contributeToHistogram(...)  // This is allowed.
      }
    }
    register('example-operation', ExampleOperation);

    privateAggregation.contributeToHistogram(...)  // This would cause an error.
    </pre>
    So, Shared Storage sets the [=PrivateAggregation/scoping details=]
    immediately after the initial execution of the module script is complete.
</div>

For any [=batching scope=] returned by the [=scoping details/get batching scope
steps=], the [=process contributions for a batching scope=] steps should later
be performed given that same batching scope, the global scope's [=relevant
settings object=]'s [=environment settings object/origin=], some [=context
type=] and a timeout (or null).

Note: This last requirement means that global scopes with different origins
    cannot share the same batching scope, see [Same-origin
    policy](#same-origin-policy) discussion.

For any [=debug scope=] returned by the [=scoping details/get debug scope
steps=], the [=mark a debug scope complete=] steps should later be performed
given that same [=debug scope=].

Note: A later algorithm [=asserts=] that, for any [=contribution cache entry=]
    in the [=contribution cache=], the [=mark a debug scope complete=] steps
    were performed given the entry's [=contribution cache entry/debug scope=]
    before the [=process contributions for a batching scope=] steps are
    performed given the entry's [=contribution cache entry/batching scope=].

Overriding `contributeToHistogramOnEvent()` processing {#contributetohistogramonevent}
--------------------------------------------------------------------------------------

Each API may also set the [=PrivateAggregation/should perform default
contributeToHistogramOnEvent() processing=] algorithm for the
{{PrivateAggregation}} object it exposes. This hook enables the embedding API to
override processing for any {{PrivateAggregation/
contributeToHistogramOnEvent()}} call it wants to.

This algorithm should return true to indicate that the regular processing
defined in this spec should occur (for that call). It should return an
[=exception=] to indicate an error has occurred in the embedding API's
processing. Alternatively, it should return false to indicate that the embedding
API will process the call, but no [=exception=] should be [=exception/thrown=].

If the embedding API overrides processing for a call (i.e. the algorithm does
not return true), it should  accept any `event` that is a [=string/
concatenation=] of « "<code>reserved.</code>", |errorEvent| » where |errorEvent|
is an [=internal error event=] and should accept any `contribution` with a
[=converted to a JavaScript value|JavaScript value=] that is [=converted to an
IDL value|convertible=] to the IDL type {{PAHistogramContribution}}. That is, it
should not return an [=exception=] in those cases. However, the embedding API
may accept additional `event`s or `contribution`s that would not be accepted by
the default processing defined in this spec.

If the embedding API overrides processing for a call specifying a contribution
conditional on an [=internal error event=], the embedding API should call
[=append an entry to the contribution cache=] with the appropriate entry unless
it intends to drop that contribution.

If the embedding API overrides processing for a call to support additional error
events, it must wait until the associated condition has been determined to have
occurred or not. If the custom error event was triggered, it should use
<code>[=already triggered external error=]</code> as the [=contribution cache
entry/error event=] for the associated contributions. If the custom error event
was not triggered, the contributions should be dropped and no call to [=append
an entry to the contribution cache=] should be made for those contributions.

Note also that, if the embedding API overrides processing, it must convert
`contribution` to the IDL type {{PAHistogramContribution}} before it is able to
call [=append an entry to the contribution cache=]. This applies whether the
`contribution` has a [=converted to a JavaScript value|JavaScript value=] that
is automatically [=converted to an IDL value|convertible=] to the IDL type or
not.

APIs exposing Private Aggregation {#apis-exposing-private-aggregation}
----------------------------------------------------------------------

<em>This section is non-normative.</em>

This API is currently exposed in global scopes defined in the specifications of
two APIs:
1. <a href="https://wicg.github.io/shared-storage/">Shared Storage</a> and
1. <a href="https://wicg.github.io/turtledove/">Protected Audience</a>.

Structures {#structures}
========================

<h3 dfn-type=dfn export>Batching scope</h3>
A batching scope is a <a spec=HTML>unique internal value</a> that identifies
which {{PAHistogramContribution}}s should be sent in the same [=aggregatable
report=] unless their [=aggregatable report/debug details=] differ.

Issue: Unique internal value is not an exported definition. See
    <a href="https://github.com/whatwg/infra/issues/583">infra/583</a>.

<h3 dfn-type=dfn>Budgeting scope</h3>
A budgeting scope defines a maximum amount of budget that a site is permitted to
consume over a duration of time. Specifically, it defines an a upper bound on
the <math><msub><mi>L</mi><mn>1</mn></msub></math> norm of a site's
contributions' values, per API, over a rolling time window. It is a [=struct=]
with the following items:

<dl dfn-for="budgeting scope">
: <dfn>max budget</dfn>
:: A positive integer
: <dfn>duration</dfn>
:: A [=duration=]
: <dfn ignore>caller type</dfn>
:: A [=context type=]

</dl>

Issue: Currently, this spec only references [=budgeting scope/max budget=]. We
need to decide whether deleting the unused fields will improve clarity.

<h3 dfn-type=dfn>Named budget ledger</h3>
A named budget ledger tracks the remaining budget per named budget. It is a
[=map=] from [=strings|budget names=] or null to integers. The null key
represents the default budget.

<h3 dfn-type=dfn export>Debug scope</h3>
A debug scope is a <a spec=HTML>unique internal value</a> that identifies which
{{PAHistogramContribution}}s should have their [=debug details=] affected by the
presence or absence of a call to {{PrivateAggregation/enableDebugMode()}} in the
same period of execution.

<h3 dfn-type=dfn export>Scoping details</h3>
A scoping details is a [=struct=] with the following items:
<dl dfn-for="scoping details">
: <dfn export>get batching scope steps</dfn>
:: An algorithm returning a [=batching scope=]
: <dfn export>get debug scope steps</dfn>
:: An algorithm returning a [=debug scope=]

</dl>

<h3 dfn-type=dfn>Debug details</h3>
A debug details is a [=struct=] with the following items:
<dl dfn-for="debug details">
: <dfn>enabled</dfn> (default false)
:: A [=boolean=]
: <dfn>key</dfn> (default null)
:: An unsigned 64-bit integer or null. The key must be null if [=debug
    details/enabled=] is false.

</dl>

<h3 id="error-events-heading">Error events</h3>
An <dfn export>internal error event</dfn> is one of the following:
<dl dfn-for="internal error event">
: "<dfn><code>report-success</code></dfn>"
:: The report was scheduled and no contributions were dropped.
: "<dfn><code>too-many-contributions</code></dfn>"
:: The report was scheduled, but some contributions were dropped due to the
    per-report limit.
: "<dfn><code>empty-report-dropped</code></dfn>"
:: The report was not scheduled as it had no contributions.
: "<dfn><code>pending-report-limit-reached</code></dfn>"
:: The report was scheduled, but the limit of pending reports was reached. That
    is, attempting to schedule one more report would fail due to the limit.
: "<dfn><code>insufficient-budget</code></dfn>"
:: One or more contributions in the report were dropped (or the
    whole report was) as there was not enough contribution budget.
: "<dfn><code>contribution-timeout-reached</code></dfn>"
:: The context(s) associated with the report was still running when
    the contribution timeout occurred.

</dl>

An <dfn export>error event</dfn> is an [=internal error event=] or the special
value <dfn export><code>already triggered external error</code></dfn>.

Note: This special value represents any external error event that has already
    occurred. External error events are defined by embedding APIs and are
    distinct from [=internal error events=]. See
    [contributeToHistogramOnEvent()](#contributetohistogramonevent) for more
    details.

<dfn>All error events</dfn> is a [=list=] of [=error events=] that consists of
all the [=internal error events=] in the order they are defined above followed
by <code>[=already triggered external error=]</code>.

<h3 dfn-type=dfn export>Contribution cache entry</h3>
A contribution cache entry is a [=struct=] with the following items:
<dl dfn-for="contribution cache entry">
: <dfn export>contribution</dfn>
:: A {{PAHistogramContribution}}
: <dfn export>error event</dfn> (default null)
:: An [=error event=] or null.

    Note: This indicates which [=error event=] the contribution is conditional
        on, or null if the contribution is unconditional.
: <dfn export>batching scope</dfn>
:: A [=batching scope=]
: <dfn export>debug scope</dfn>
:: A [=debug scope=]
: <dfn export>debug details</dfn> (default null)
:: A [=debug details=] or null

</dl>

<h3 dfn-type=dfn>Pending contributions</h3>

A pending contributions is a [=struct=] with the following items:
<dl dfn-for="pending contributions">
: <dfn>unconditional contributions</dfn> (default: a new [=list=])
:: A [=list=] of {{PAHistogramContribution}}s
: <dfn>conditional contributions</dfn> (default: a new [=map=])
:: A [=map=] where its [=map/keys=] are [=error events=] and [=map/values=] are
    [=lists=] of {{PAHistogramContribution}}s
: <dfn>triggered error events</dfn> (default: a new [=set=])
:: A [=set=] of [=internal error events=]

</dl>

<h3 dfn-type=dfn>Aggregatable report</h3>

An aggregatable report is a [=struct=] with the following items:
<dl dfn-for="aggregatable report">
: <dfn>reporting origin</dfn>
:: An [=origin=]
: <dfn>original report time</dfn>
:: A [=moment=]
: <dfn>report time</dfn>
:: A [=moment=]
: <dfn>contributions</dfn>
:: A [=list=] of {{PAHistogramContribution}}s
: <dfn>api</dfn>
:: A [=context type=]
: <dfn>report ID</dfn>
:: A [=string=]
: <dfn>debug details</dfn>
:: A [=debug details=]
: <dfn>aggregation coordinator</dfn>
:: An [=aggregation coordinator=]
: <dfn>context ID</dfn>
:: A [=string=] or null
: <dfn>filtering ID max bytes</dfn>
:: A positive integer
: <dfn>max contributions</dfn>
:: A positive integer
: <dfn>queued</dfn>
:: A [=boolean=]

</dl>

Aggregation coordinator {#aggregation-coordinator-structure}
------------------------------------------------------------

An <dfn export>aggregation coordinator</dfn> is an [=origin=] that the [=allowed
aggregation coordinator set=] [=set/contains=].

Issue: Consider switching to the <a spec="attribution-reporting-api">suitable
origin</a> concept used by the Attribution Reporting API here and elsewhere.

Issue: Move other structures to be defined inline instead of via a header.
    Consider also removing all the subheadings.

<h3 dfn-type=dfn>Context type</h3>
A context type is a [=string=] indicating what kind of global scope the
{{PrivateAggregation}} object was exposed in. Each API exposing Private
Aggregation should pick a unique string (or multiple) for this.

Pre-specified report parameters {#pre-specified-report-parameters-structure}
----------------------------------------------------------------------------

A <dfn export>pre-specified report parameters</dfn> is a [=struct=] with the
following items:
<dl dfn-for="pre-specified report parameters">
: <dfn export>context ID</dfn> (default: null)
:: A [=string=] or null
: <dfn export>filtering ID max bytes</dfn> (default: [=default filtering ID max
    bytes=])
:: A positive integer
: <dfn export>max contributions</dfn> (default: null)
:: A positive integer or null

</dl>

Storage {#storage}
==================

A [=user agent=] holds an <dfn>aggregatable report cache</dfn>, which is a
[=list=] of [=aggregatable reports=].

A [=user agent=] holds an <dfn>aggregation coordinator map</dfn>, which is a
[=map=] from [=batching scopes=] to [=aggregation coordinators=].

A [=user agent=] holds a <dfn>pre-specified report parameters map</dfn>, which
is a [=map=] from [=batching scopes=] to [=pre-specified report parameters=].

A [=user agent=] holds a <dfn>named budget ledgers map</dfn>, which is a [=map=]
from [=batching scopes=] to [=lists=] of [=named budget ledgers=].

Issue: Move [=named budget ledgers map=] to a field of {{PrivateAggregation}}
because it does not outlive an isolated context.

A [=user agent=] holds a <dfn>contribution cache</dfn>, which is a [=list=] of
[=contribution cache entries=].

A [=user agent=] holds a <dfn>debug scope map</dfn>, which is a [=map=] from
[=debug scopes=] to [=debug details=].

Issue: Elsewhere, link to definition when using [=user agent=].

Clearing storage {#clearing-storage}
----------------------------------------

The user agent must expose controls that allow the user to delete data from
the [=aggregatable report cache=] as well as any contribution history data
stored for the [=query the budget=] algorithm.

The user agent may expose controls that allow the user to delete data from the
[=contribution cache=], the [=debug scope map=] and the [=pre-specified report
parameters map=].

Constants {#constants}
======================

<dfn export>Default filtering ID max bytes</dfn> is a positive integer
controlling the max bytes used if none is explicitly chosen. Its value is 1.

<dfn export>Valid filtering ID max bytes range</dfn> is a [=set=] of positive
integers controlling the allowable values of max bytes. Its value is [=the
inclusive range|the range=] 1 to 8, inclusive.

Issue: Consider adding more constants.

[=Implementation-defined=] values {#implementation-defined-values}
==================================================================

<dfn>Allowed aggregation coordinator set</dfn> is a [=set=] of [=origins=] that
controls which [=origins=] are valid [=aggregation coordinators=]. Every
[=set/item=] in this [=set=] must be a [=potentially trustworthy origin=].

<dfn>Default aggregation coordinator</dfn> is an [=aggregation coordinator=]
that controls which is used for a report if none is explicitly selected.

<dfn>Maximum maxContributions</dfn> is a positive integer that defines an upper
bound on the number of contributions per [=aggregatable report=].

<dfn>Default maxContributions by API</dfn> is a [=map=] from [=context types=]
to positive integers. Semantically, it defines the default number of
contributions per report for every kind of calling context, e.g. Shared Storage.
The values in this map are used when callers do not specifically request another
value. Each value in this map must be less than or equal to [=maximum
maxContributions=].

<dfn>Minimum report delay</dfn> is a non-negative [=duration=] that controls the
minimum delay to deliver an [=aggregatable report=].

<dfn>Randomized report delay</dfn> is a positive [=duration=] that controls the
random delay to deliver an [=aggregatable report=]. This delay is additional to
the [=minimum report delay=].

<dfn>All budgeting scopes</dfn> is a non-empty [=list=] of [=budgeting scopes=].

<div class="advisement"><span class="marker">WARNING:</span>
Implementers must only use [=budgeting scope/max budgets=] of the form
<math><msup><mn>2</mn><mn>k</mn></msup></math>, where
<math><mn>0</mn><mo>≤</mo><mi>k</mi><mo>≤</mo><mn>52</mn></math>.  This ensures
that all budget fractions
<math><mi>n</mi><mo>/</mo><msup><mn>2</mn><mi>k</mi></msup></math> can be
represented exactly by a {{double}}, for all integral <math><mi>n</mi></math> in
the range
<math><mo>[</mo><mn>0</mn><mo>,</mo><msup><mn>2</mn><mi>k</mi></msup><mo>]</mo></math>.
</div>

<dfn>Maximum number of named budgets</dfn> is a positive integer that defines an
upper bound on the number of named budgets that may be configured per [=batching
scope=].

<dfn>Maximum length of budget name</dfn> is a positive integer that defines an
upper bound on the [=string/length=] of a budget name.

Permissions Policy integration {#permissions-policy-integration}
================================================================

This specification defines a [=policy-controlled feature=] identified by the
string "<code><dfn export>private-aggregation</dfn></code>". Its
[=policy-controlled feature/default allowlist=] is "`*`".

Note: The [=PrivateAggregation/allowed to use=] field is set by other
    specifications that integrate with this API according to this
    [=policy-controlled feature=].

Algorithms {#algorithms}
====================

To <dfn>serialize an integer</dfn>, represent it as a [=string=] of the shortest
possible decimal number.

Issue: This would ideally be replaced by a more descriptive algorithm in Infra.
    See <a href="https://github.com/whatwg/infra/issues/201">infra/201</a>.

Exported algorithms {#exported-algorithms}
------------------------------------------

Note: These algorithms allow other specifications to integrate with this API.

<div algorithm>
To <dfn export>get the privateAggregation</dfn> given a
{{PrivateAggregation}} |this|:
1. Let |scopingDetails| be |this|'s [=PrivateAggregation/scoping details=].
1. If |scopingDetails| is null, [=exception/throw=] a "{{NotAllowedError}}"
    {{DOMException}}.

    Note: This indicates the API is not yet available, for example, because the
        initial execution of the script after loading is not complete.

    Issue: Consider improving developer ergonomics here (e.g. a way to detect
        this case).
1. If |this|'s [=PrivateAggregation/allowed to use=] is false, [=exception/
    throw=] an "{{InvalidAccessError}}" {{DOMException}}.
1. Return |this|.

Issue: Ensure errors are of an appropriate type, e.g. {{InvalidAccessError}} is
    deprecated.
</div>

<div algorithm>
To <dfn export>append an entry to the contribution cache</dfn> given a
[=contribution cache entry=] |entry|:
1. [=list/Append=] |entry| to the [=contribution cache=].

</div>

<div algorithm>
To <dfn export>get a debug details</dfn> given a [=debug scope=]
|debugScope|, perform the following steps. They return a [=debug details=].
1. If [=debug scope map=][|debugScope|] [=map/exists=], return
    [=debug scope map=][|debugScope|].
1. Otherwise, return a new [=debug details=].

</div>

<div algorithm>
To <dfn export>mark a debug scope complete</dfn> given a [=debug
scope=] |debugScope| and an optional [=debug details=] or null
|debugDetailsOverride| (default null):
1. Let |debugDetails| be |debugDetailsOverride|.
1. If [=debug scope map=][|debugScope|] [=map/exists=]:
    1. [=Assert=]: |debugDetailsOverride| is null.

        Note: The override can be provided if the debug details have not been
            set otherwise.
    1. Set |debugDetails| to [=debug scope map=][|debugScope|].
    1. [=map/Remove=] [=debug scope map=][|debugScope|].
    1. If |debugDetails|'s [=debug details/key=] is not null, [=assert=]:
        |debugDetails|'s [=debug details/enabled=] is true.
1. If |debugDetails| is null, set |debugDetails| to a new [=debug details=].
1. [=list/iterate|For each=] |entry| of the [=contribution cache=]:
    1. If |entry|'s [=contribution cache entry/debug scope=] is |debugScope|,
        set |entry|'s [=contribution cache entry/debug details=] to
        |debugDetails|.

</div>

<div algorithm>
To <dfn export>determine if a report should be sent deterministically</dfn>
given a [=pre-specified report parameters=] |preSpecifiedParams| and a [=context
type=] |api|, perform the following steps. They return a [=boolean=]:
1. If |preSpecifiedParams|' [=pre-specified report parameters/context ID=] is
    not null, return true.
1. If |preSpecifiedParams|' [=pre-specified report parameters/filtering ID max
    bytes=] is not the [=default filtering ID max bytes=], return true.
1. Let |effectiveMaxContributions| be the result of [=determining the max
    contributions=] with |api| and |preSpecifiedParams|' [=pre-specified report
    parameters/max contributions=].
1. Let |defaultMaxContributions| be [=default maxContributions by API=][|api|].
1. If |effectiveMaxContributions| is not |defaultMaxContributions|, return true.
1. Return false.

Note: It is sometimes necessary to send a 'null report' to conceal the fact that
 there were no contributions. For instance, it's possible that budget, which is
 cross-site data in its own right, was insufficient for the requested
 contributions. Alternatively, the caller might have chosen to make no
 contributions after reading cross-site data. In these kinds of scenarios, the
 absence of a report could reveal cross-site data to the reporting endpoint. See
 [Protecting against leaks via the number of
 reports](#protecting-against-leaks-via-the-number-of-reports).

</div>

<div algorithm>
To <dfn export>process contributions for a batching scope</dfn> given
a [=batching scope=] |batchingScope|, an [=origin=] |reportingOrigin|, a
[=context type=] |contextType| and a [=moment=] or null |timeout|:

Note: Embedding APIs are expected to set |timeout| to null if a report isn't
    [=determine if a report should be sent deterministically|deterministic=] or
    if the timeout was already reached, i.e. if it caused this call to be
    triggered. (A timeout always has to be set for [=determine if a report
    should be sent deterministically|deterministic=] reports.)

1. Let |batchEntries| be a new [=list=].
1. [=list/iterate|For each=] |entry| of the [=contribution cache=]:
    1. If |entry|'s [=contribution cache entry/batching scope=] is
        |batchingScope|:
        1. [=Assert=]: |entry|'s [=contribution cache entry/debug details=] is
            not null.

            Note: This asserts that the [=mark a debug scope complete=] steps
                were run before the [=process contributions for a batching
                scope=] steps.

        1. [=list/Append=] |entry| to |batchEntries|.
1. Let |aggregationCoordinator| be the [=default aggregation coordinator=].
1. If [=aggregation coordinator map=][|batchingScope|] [=map/exists=]:
    1. Set |aggregationCoordinator| to [=aggregation coordinator
        map=][|batchingScope|].
    1. [=map/Remove=] [=aggregation coordinator map=][|batchingScope|].
1. Let |preSpecifiedParams| be a new [=pre-specified report parameters=].
1. If [=pre-specified report parameters map=][|batchingScope|] [=map/exists=]:
    1. Set |preSpecifiedParams| to [=pre-specified report parameters
        map=][|batchingScope|].
    1. [=map/Remove=] [=pre-specified report parameters map=][|batchingScope|].
1. Let |isDeterministicReport| be the result of [=determining if a report should
    be sent deterministically=] given |preSpecifiedParams| and |contextType|.
1. If |isDeterministicReport| is false, [=assert=]: |timeout| is null.

    Note: Timeouts can only be used for deterministic reports.
1. If |batchEntries| [=list/is empty=] and |isDeterministicReport| is false,
    return.
1. Let |batchedContributions| be a new [=ordered map=].
1. [=list/iterate|For each=] |entry| of |batchEntries|:
    1. [=list/Remove=] |entry| from the [=contribution cache=].
    1. Let |debugDetails| be |entry|'s [=contribution cache entry/debug
        details=].
    1. If |batchedContributions|[|debugDetails|] does not [=map/exist=], [=map/
        set=] |batchedContributions|[|debugDetails|] to a new [=pending
        contributions=].
    1. If |entry|'s [=contribution cache entry/error event=] is null:
        1. [=list/Append=] |entry|'s [=contribution cache entry/contribution=]
            to |batchedContributions|[|debugDetails|]'s [=pending contributions/
            unconditional contributions=].
    1. Otherwise:
        1. Let |conditionalContributions| be
            |batchedContributions|[|debugDetails|]'s [=pending contributions/
            conditional contributions=].
        1. If |conditionalContributions|[|errorEvent|] does not [=map/exist=],
            [=map/set=] |conditionalContributions|[|errorEvent|] to a new
            [=list=].
        1. [=list/Append=] |entry|'s [=contribution cache entry/contribution=]
            to |conditionalContributions|[|errorEvent|].
1. If |batchedContributions| [=map/is empty=]:
    1. Let |debugDetails| be a new [=debug details=].
    1. Set |batchedContributions|[|debugDetails|] to a new [=pending
        contributions=].
1. [=map/iterate|For each=] |debugDetails| → |pendingContributions| of
    |batchedContributions|:
    1. Perform the [=report creation and scheduling steps=] with
        |batchingScope|, |reportingOrigin|, |contextType|,
        |pendingContributions|, |debugDetails|, |aggregationCoordinator|,
        |preSpecifiedParams| and |timeout|.

Note: These steps break up the contributions based on their [=debug details=] as
    each report can only have one set of metadata.
</div>

<div algorithm>
To <dfn export>determine if an origin is an aggregation coordinator</dfn> given
an [=origin=] |origin|, perform the following steps. They return a [=boolean=].

1. Return whether |origin| is an [=aggregation coordinator=].

</div>

<div algorithm>
To <dfn export>obtain the Private Aggregation coordinator</dfn> given a
{{USVString}} |originString|, perform the following steps. They return an
[=aggregation coordinator=] or a {{DOMException}}.

1. Let |url| be the result of running the [=URL parser=] on |originString|.
1. If |url| is failure or null, return a new {{DOMException}} with name
    "`SyntaxError`".

    Issue: Consider throwing an error if the path is not empty.
1. Let |origin| be |url|'s [=url/origin=].
1. If the result of [=determining if an origin is an aggregation coordinator=]
    given |origin| is false, return a new {{DOMException}} with name
    "`DataError`".
1. Return |origin|.

</div>

<div algorithm>
To <dfn export>set the aggregation coordinator for a batching scope</dfn> given
an [=origin=] |origin| and a [=batching scope=] |batchingScope|:

1. [=Assert=]: |origin| is an [=aggregation coordinator=].
1. [=map/Set=] [=aggregation coordinator map=][|batchingScope|] to |origin|.

</div>

Issue: Elsewhere, surround algorithms in a `<div algorithm>` block to match, and
    add styling for all algorithms per
    [bikeshed/1472](https://github.com/speced/bikeshed/issues/1472).

<div algorithm>
To <dfn export>set the pre-specified report parameters for a batching
scope</dfn> given a [=pre-specified report parameters=] |params| and a
[=batching scope=] |batchingScope|:

1. Let |contextId| be |params|' [=pre-specified report parameters/context ID=].
1. [=Assert=]: |contextId| is null or |contextId|'s [=string/length=] is not
    larger than 64.
1. Let |filteringIdMaxBytes| be |params|' [=pre-specified report parameters/
    filtering ID max bytes=].
1. [=Assert=]: |filteringIdMaxBytes| is [=set/contained=] in the [=valid
    filtering ID max bytes range=]
1. Let |maxContributions| be |params|' [=pre-specified report parameters/max
    contributions=].
1. [=Assert=]: |maxContributions| is null or greater than zero.
1. [=map/Set=] [=pre-specified report parameters map=][|batchingScope|] to
    |params|.

</div>

<div algorithm>
To <dfn export>validate a histogram contribution</dfn> given a
{{PAHistogramContribution}} |contribution| and a [=scoping details=]
|scopingDetails|, perform the following steps. They return a [=contribution
cache entry=] or an [=exception=].

1. If |contribution|["{{PAHistogramContribution/bucket}}"] is not [=set/
    contained=] in [=the exclusive range|the range=] 0 to 2<sup>128</sup>,
    exclusive, return a {{RangeError}}.
1. If |contribution|["{{PAHistogramContribution/value}}"] is negative, return a
    {{RangeError}}.
1. Let |batchingScope| be the result of running |scopingDetails|' [=scoping
    details/get batching scope steps=].
1. Let |filteringIdMaxBytes| be the [=default filtering ID max bytes=].
1. If [=pre-specified report parameters map=][|batchingScope|] [=map/exists=]:
    1. Set |filteringIdMaxBytes| to [=pre-specified report parameters
        map=][|batchingScope|]'s [=pre-specified report parameters/filtering ID
        max bytes=].
1. If |contribution|["{{PAHistogramContribution/filteringId}}"] is not [=set/
    contained=] in [=the exclusive range|the range=] 0 to
    256<sup>|filteringIdMaxBytes|</sup>, exclusive, return a {{RangeError}}.
1. Return a new [=contribution cache entry=] with the items:
    : [=contribution cache entry/contribution=]
    :: |contribution|
    : [=contribution cache entry/batching scope=]
    :: |batchingScope|
    : [=contribution cache entry/debug scope=]
    :: The result of running |scopingDetails|' [=scoping details/get debug scope
        steps=].

Issue: Ensure errors are of an appropriate type, e.g. {{InvalidAccessError}} is
    deprecated.

</div>

Scheduling reports {#scheduling-reports}
----------------------------------------

<div algorithm>
To perform the <dfn>report creation and scheduling steps</dfn> with a
[=batching scope=] |batchingScope|, an [=origin=] |reportingOrigin|, a [=context
type=] |api|, a [=pending contributions=] |pendingContributions|, a [=debug
details=] |debugDetails|, an [=aggregation coordinator=]
|aggregationCoordinator|, a [=pre-specified report parameters=]
|preSpecifiedParams| and a [=moment=] or null |timeout|:

1. [=Assert=]: |reportingOrigin| is a [=potentially trustworthy origin=].
1. Optionally, return.

    Note: This [=implementation-defined=] condition is intended to allow [=user
        agents=] to drop reports for a number of reasons, for example user
        opt-out, an origin not being
        <a href="https://github.com/privacysandbox/attestation">enrolled</a> or
        a limit on pending reports being reached.
1. Let |currentWallTime| be the [=current wall time=].
1. Let |allUnmergedContributions| be the result of [=compiling all unmerged
    contributions=], given |reportingOrigin|, |api|, |pendingContributions|,
    |preSpecifiedParams|, |timeout| and |currentWallTime|.
1. Let |isDeterministicReport| be the result of [=determining if a report
    should be sent deterministically=] given |preSpecifiedParams| and |api|.
1. Let |effectiveMaxContributions| be the result of [=determining the max
    contributions=] with |api| and |preSpecifiedParams|' [=pre-specified
    report parameters/max contributions=].
1. Let |keptMergeKeys| be a new [=set=].
1. [=list/For each=] |contribution| of |allUnmergedContributions|:
    1. Let |mergeKey| be |contribution|'s [=merge key=].
    1. If |keptMergeKeys|' [=list/size=] is |effectiveMaxContributions| and
        |keptMergeKeys| does not [=list/contain=] |mergeKey|, [=iteration/
        continue=].
    1. Otherwise, [=set/append=] |mergeKey| to |keptMergeKeys|.
1. [=list/Remove=] all items that have a [=merge key=] that is not [=list/
    contained=] in |keptMergeKeys| from |allUnmergedContributions|.
1. Let |ledgers| be a new [=list=].
1. If [=named budget ledgers map=][|batchingScope|] [=map/exists=]:
    1. Let |ledgers| be  [=named budget ledgers map=][|batchingScope|].
1. Let |finalBudgetResults| be the result of [=querying the budget=] given
    |allUnmergedContributions|, |ledgers|, |reportingOrigin|, |api|,
    |currentWallTime| and true.
1. [=Assert=]: |finalBudgetResults|' [=list/size=] equals
    |allUnmergedContributions|' [=list/size=].
1. [=set/For each=] |i| of [=the exclusive range|the range=] 0 to
    |finalBudgetResults|' [=list/size=], exclusive:
    1. If |finalBudgetResults|[|i|] is false, set
        |allUnmergedContributions|[i]'s {{PAHistogramContribution/value}} to 0.
1. [=list/Remove=] all items from |allUnmergedContributions| that have a
    {{PAHistogramContribution/value}} of 0.
1. Let |mergedContributionsMap| be a new [=ordered map=].
1. [=list/For each=] |contribution| of |allUnmergedContributions|:
    1. Let |mergeKey| be |contribution|'s [=merge key=].
    1. If |mergedContributionsMap|[|mergeKey|] [=map/exists=], add
        |contribution|'s {{PAHistogramContribution/value}} to
        |mergedContributionsMap|[|mergeKey|]'s {{PAHistogramContribution/
        value}}.
    1. Otherwise, [=map/set=] |mergedContributionsMap|[|mergeKey|] to
        |contribution|.
1. Let |mergedContributions| be the |mergedContributionsMap|'s [=map/values=].
1. [=Assert=]: |mergedContributions| has a [=list/size=] less than or equal to
    |effectiveMaxContributions|,
1. If |mergedContributions| [=list/is empty=] and |isDeterministicReport| is
    false, return.
1. Let |report| be the result of [=obtaining an aggregatable report=] given
    |reportingOrigin|, |api|, |mergedContributions|, |debugDetails|,
    |aggregationCoordinator|, |preSpecifiedParams|, |timeout| and
    |currentWallTime|.
1. [=set/Append=] |report| to the user agent's [=aggregatable report cache=].

</div>

<div algorithm>
To <dfn>compile all unmerged contributions</dfn> given an [=origin=]
|reportingOrigin|, a [=context type=] |api|, a [=pending contributions=]
|pendingContributions|, a [=pre-specified report parameters=]
|preSpecifiedParams|, a [=moment=] or null |timeout|, and a [=moment=]
|currentWallTime|, perform the following steps. They return a [=list=] of
{{PAHistogramContribution}}s.

1. Let |wasTimeoutReached| be the [=boolean=] indicating whether both
    |isDeterministicReport| is true and |timeout| is null.

    Issue: Update the timeout being sent from Shared Storage to align.
1. [=Record the internal error event result=] given |pendingContributions|,
    "<code>[=internal error event/contribution-timeout-reached=]</code>" and
    |wasTimeoutReached|.
1. Let |ledgers| be a new [=list=].
1. If [=named budget ledgers map=][|batchingScope|] [=map/exists=]:
    1. Let |ledgers| be  [=named budget ledgers map=][|batchingScope|].
1. Let |provisionalBudgetResults| be the result of [=querying the budget=] given
    |pendingContributions|' [=pending contributions/unconditional
    contributions=], |ledgers|, |reportingOrigin|, |api|, |currentWallTime| and
    false.

1. [=Assert=]: |provisionalBudgetResults|' [=list/size=] equals
    |pendingContributions|' [=pending contributions/unconditional
    contributions=]' [=list/size=].
1. [=set/For each=] |i| of [=the exclusive range|the range=] 0 to
    |provisionalBudgetResults|' [=list/size=], exclusive:
    1. If |provisionalBudgetResults|[|i|] is false, set |pendingContributions|'
        [=pending contributions/unconditional contributions=][|i|]'s
        {{PAHistogramContribution/value}} to 0.
1. [=list/Remove=] all items from |pendingContributions|' [=pending
    contributions/unconditional contributions=] that have a
    {{PAHistogramContribution/value}} of 0.
1. Let |insufficientBudget| be a [=boolean=] indicating whether any value in
    |provisionalBudgetResults| is false.
1. [=Record the internal error event result=] given |pendingContributions|,
    "<code>[=internal error event/insufficient-budget=]</code>" and
    |insufficientBudget|.
1. Let |pendingReportLimitReached| be a [=boolean=] determined by an
    [=implementation-defined=] algorithm.

    Note: This is intended to indicate when a limit on the number of reports
        simultaneously pending on a budget query was reached (but not exceeded).
1. [=Record the internal error event result=] given |pendingContributions|,
    "<code>[=internal error event/pending-report-limit-reached=]</code>" and
    |pendingReportLimitReached|.
1. Let |isEmptyAndWouldBeDropped| be a [=boolean=] indicating whether both
    |isDeterministicReport| is false and |pendingContributions|' [=pending
    contributions/unconditional contributions=] [=list/is empty=].
1. [=Record the internal error event result=] given |pendingContributions|,
    "<code>[=internal error event/empty-report-dropped=]</code>" and
    |isEmptyAndWouldBeDropped|.
1. Let |effectiveMaxContributions| be the result of [=determining the max
    contributions=] with |api| and |preSpecifiedParams|' [=pre-specified
    report parameters/max contributions=].
1. Let |tooManyContributions| be false.
1. Let |provisionallyApprovedMergeKeys| be a new [=set=].
1. [=list/For each=] |contribution| of |pendingContributions|' [=pending
    contributions/unconditional contributions=]:
    1. Let |mergeKey| be |contribution|'s [=merge key=].
    1. If |provisionallyApprovedMergeKeys|' [=list/size=] is
        |effectiveMaxContributions| and |provisionallyApprovedMergeKeys| does
        not [=list/contain=] |mergeKey|, set |tooManyContributions| to true.
    1. Otherwise, [=set/append=] |mergeKey| to |provisionallyApprovedMergeKeys|.
1. [=Record the internal error event result=] given |pendingContributions|,
    "<code>[=internal error event/too-many-contributions=]</code>" and
    |tooManyContributions|.
1. [=list/Remove=] all items that have a [=merge key=] that is not [=list/
    contained=] in |provisionallyApprovedMergeKeys| from |pendingContributions|'
    [=pending contributions/unconditional contributions=].
1. Let |reportSuccess| be the [=boolean=] indicating whether <em>none</em> of
    the following are true: |isEmptyAndWouldBeDropped|, |tooManyContributions|,
    |insufficientBudget|, |pendingReportLimitReached|.
1. [=Record the internal error event result=] given |pendingContributions|,
    "<code>[=internal error event/report-success=]</code>" and
    |reportSuccess|.
1. Let |allUnmergedContributions| be a new [=list=].
1. [=list/For each=] |errorEvent| of [=all error events=]:
    1. If |pendingContributions|' [=pending contributions/conditional
        contributions=][|errorEvent|] does not [=map/exist=], [=iteration/
        continue=].
    1. [=Assert=]: |pendingContributions|' [=pending contributions/triggered
        error events=] [=set/contains=] |errorEvent| or |errorEvent| is
        "<code>[=already triggered external error=]</code>".

        Note: When an internal error event is determined to not be triggered,
            its conditional contributions are removed by [=record the internal
            error event result=]
    1. [=list/Extend=] |allUnmergedContributions| with |pendingContributions|'
        [=pending contributions/conditional contributions=][|errorEvent|].
1. [=list/Extend=] |allUnmergedContributions| with |pendingContributions|'
    [=pending contributions/unconditional contributions=].

    Note: Unconditional contributions come last to prioritize successful
        measurement of errors.
1. Return |allUnmergedContributions|.

</div>

<div algorithm>
Each {{PAHistogramContribution}} |contribution| has a <dfn>merge key</dfn> that
is the following [=tuple=]: (|contribution|'s {{PAHistogramContribution/
bucket}}, |contribution|'s {{PAHistogramContribution/filteringId}}).

Note: Two {{PAHistogramContribution}}s for the same report can be merged if and
    only if they have the same merge key.

</div>

<div algorithm>
To <dfn>query the budget</dfn> given a [=list=] of {{PAHistogramContribution}}s
|contributions|, a [=list=] of [=named budget ledgers=]
|remainingBudgetLedgers|, an [=origin=] |origin|, a [=context type=] |api|, a
[=moment=] |currentTime|, and a [=boolean=] |consumeIfPermitted|, perform the
following steps. They return a [=list=] of [=booleans=] with the same
[=list/size=] as |contributions|.

1. If |remainingBudgetLedgers| is [=list/empty=]:
    1. [=list/For each=] |budgetingScope| of [=all budgeting scopes=]:
        1. Let |remainingBudgetLedger| be a new [=named budget ledger=].
        1. [=map/Set=] |remainingBudgetLedger|[null] to |budgetingScope|'s
            [=budgeting scope/max budget=].
        1. [=list/Append=] |remainingBudgetLedger| to |remainingBudgetLedgers|.
1. Let |numScopes| be the [=list/size=] of [=all budgeting scopes=].
1. [=Assert=] that |numScopes| is equal to the [=list/size=] of
    |remainingBudgetLedgers|.
1. [=list/For each=] |i| in [=the exclusive range|the range=] from 0 to
    |numScopes|, exclusive:
    1. Let |budgetingScope| be [=all budgeting scopes=][|i|].
    1. Let |duration| be |budgetingScope|'s [=budgeting scope/duration=].
    1. Let |remainingBudgetLedger| be |remainingBudgetLedgers|[|i|].
    1. [=map/For each=] |name| → |maxBudget| of |remainingBudgetLedger|:
        1. Let |budgetConsumed| be an integer determined by an
            [=implementation-defined=] algorithm given |origin|, |api|, |name|,
            and |duration|. This algorithm should return a value greater than or
            equal to the sum of the values of contributions that referenced the
            named budget |name| and were accepted in the last |duration| units
            of time. The contributions must have originated from an isolated
            context of type |api| that was loaded from |origin|.
        1. [=Assert=] that |maxBudget| is less than or equal to
            |budgetingScope|'s [=budgeting scope/max budget=].
        1. If |budgetConsumed| is greater than or equal to |maxBudget|:
            1. [=map/Set=] |remainingBudgetLedger|[|name|] to 0.
        1. Otherwise:
            1. [=map/Set=] |remainingBudgetLedger|[|name|] to |maxBudget| -
                |budgetConsumed|.

    Note: We have now adjusted |remainingBudgetLedgers| based on historical
    budget consumption. Next, we will accept or reject contributions by
    comparing running totals of consumed budget to the values in
    |remainingBudgetLedgers|.

1. Let |resultForEachContribution| be a new [=list=] of [=booleans=].
1. Let |ledgerConsumed| be a new [=named budget ledger=].
1. [=list/For each=] |contribution| of |contributions|:
    1. Let |name| be |contribution|'s {{PAHistogramContribution/namedBudget}}.
    1. If |ledgerConsumed|[|name|] does not [=map/exist=], [=map/set=] it to
        zero.
    1. Let |dropContribution| be false.
    1. [=list/For each=] |remainingBudgetLedger| of |remainingBudgetLedgers|:
        1. [=Assert=] that |remainingBudgetLedger|[|name|] [=map/exists=].
        1. Let |proposedBudget| be |ledgerConsumed|[|name|] + |contribution|'s
            {{PAHistogramContribution/value}}.
        1. If |proposedBudget| is greater than |remainingBudgetLedger|[|name|]:
            1. Set |dropContribution| to true.
            1. [=iteration/Break=].
    1. If |dropContribution|:
        1. [=list/Append=] false to |resultForEachContribution|.
        1. [=iteration/Continue=].
    1. [=list/For each=] |remainingBudgetLedger| of |remainingBudgetLedgers|:
        1. Let |value| be |contribution|'s {{PAHistogramContribution/value}}.
        1. [=map/Set=] |remainingBudgetLedger|[|name|] to
            |remainingBudgetLedger|[|name|] - |value|.
        1. [=map/Set=] |ledgerConsumed|[|name|] to |ledgerConsumed|[|name|] +
            |value|.
    1. [=list/Append=] true to |resultForEachContribution|.
1. If |consumeIfPermitted|, consume budget using an [=implementation-defined=]
    algorithm given |ledgerConsumed|, |origin|, |api|, and |currentTime|.
1. Return |resultForEachContribution|.

</div>

<div algorithm>
To <dfn>record the internal error event result</dfn> given a [=pending
contributions=] |pendingContributions|, an [=internal error event=]
|errorEvent| and a [=boolean=] |wasTriggered|, perform the following steps:
1. If |wasTriggered|, [=set/append=] |errorEvent| to |pendingContributions|'
    [=pending contributions/triggered error events=].
1. Otherwise, [=map/remove=] |pendingContributions|' [=pending contributions/
    conditional contributions=][|errorEvent|].

</div>

<div algorithm>
To <dfn>obtain an aggregatable report</dfn> given an [=origin=]
|reportingOrigin|, a [=context type=] |api|, a [=list=] of
{{PAHistogramContribution}}s |contributions|, a [=debug details=]
|debugDetails|, an [=aggregation coordinator=] |aggregationCoordinator|, a
[=pre-specified report parameters=] |preSpecifiedParams|, a [=moment=] or null
|timeout| and a [=moment=] |currentTime|,
perform the following steps. They return an [=aggregatable report=].
1. [=Assert=]: |reportingOrigin| is a [=potentially trustworthy origin=].
1. Let |reportTime| be the result of running [=obtain a report delivery time=]
    given |currentTime| and |timeout|.
1. Let |report| be a new [=aggregatable report=] with the items:
    : [=aggregatable report/reporting origin=]
    :: |reportingOrigin|
    : [=aggregatable report/original report time=]
    :: |reportTime|
    : [=aggregatable report/report time=]
    :: |reportTime|
    : [=aggregatable report/contributions=]
    :: |contributions|
    : [=aggregatable report/api=]
    :: |api|
    : [=aggregatable report/report ID=]
    :: The result of [=generating a random UUID=].
    : [=aggregatable report/debug details=]
    :: |debugDetails|
    : [=aggregatable report/aggregation coordinator=]
    :: |aggregationCoordinator|
    : [=aggregatable report/context ID=]
    :: |preSpecifiedParams|' [=pre-specified report parameters/context ID=]
    : [=aggregatable report/filtering ID max bytes=]
    :: |preSpecifiedParams|' [=pre-specified report parameters/filtering ID max
        bytes=]
    : [=aggregatable report/max contributions=]
    :: The result of [=determining the max contributions=] with |api| and
        |preSpecifiedParams|' [=pre-specified report parameters/max
        contributions=].
    : [=aggregatable report/queued=]
    :: false
1. Return |report|.

</div>

<div algorithm>
To <dfn>obtain a report delivery time</dfn> given a [=moment=]
|currentTime| and a [=moment=] or null |timeout|, perform the following steps.
They return a [=moment=].

1. If |timeout| is not null:
    1. Return |timeout|.
1. If [=automation local testing mode enabled=] is true, return
    |currentTime|.
1. Let |r| be a random double between 0 (inclusive) and 1 (exclusive) with
    uniform probability.
1. Return |currentTime| + [=minimum report delay=] + |r| * [=randomized report
    delay=].

</div>

<div algorithm>
To <dfn>determine the max contributions</dfn> given a [=context type=] |api| and
a positive integer or null |maxContributions|, perform the following steps. They
return a positive integer.
1. If |maxContributions| is null, return [=default maxContributions by
    API=][|api|].
1. If |maxContributions| is greater than [=maximum maxContributions=], return
    [=maximum maxContributions=].
1. Return |maxContributions|.

</div>

Sending reports {#sending-reports}
----------------------------------

Note: This section is largely copied from the
    <a href="https://wicg.github.io/attribution-reporting-api/">Attribution
    Reporting API spec</a>, adapting as necessary.


Issue: Do we have to use the [=queue a task=] algorithm here?

The user agent must periodically [=attempt to queue reports for sending=] given
its [=aggregatable report cache=].

<div algorithm>
To <dfn>attempt to queue reports for sending</dfn> given a [=list=] of
[=aggregatable reports=] |reports|:
1. [=list/iterate|For each=] |report| of |reports|, run these steps [=in
    parallel=]:
    1. Run these steps, but [=abort when=] the [=user agent=] shuts down:
        1. If |report|'s [=aggregatable report/queued=] value is true, return.
        1. Set |report|'s [=aggregatable report/queued=] value to true.
        1. Let |currentWallTime| be the [=current wall time=].
        1. If |report|'s [=aggregatable report/report time=] is before
            |currentWallTime|, set |report|'s [=aggregatable report/report
            time=] to |currentWallTime| plus an [=implementation-defined=]
            random non-negative [=duration=].

            Note: On startup, it is possible the user agent will need to send
                many reports whose report times passed while the browser was
                closed. Adding random delay prevents temporal joining of
                reports.
        1. Wait until the [=current wall time=] is equal to or after |report|'s
            [=aggregatable report/report time=].
        1. Optionally, wait a further [=implementation-defined=] non-negative
            [=duration=].

            Note: This is intended to allow user agents to optimize device
                resource usage and wait for the user agent to be online.
        1. Run [=attempt to deliver a report=] with |report|.
    1. [=If aborted=], set |report|'s [=aggregatable report/queued=] value to
        false.

        Note: It might be more practical to perform this step when the [=user
            agent=] next starts up.

</div>

<div algorithm>
To <dfn>attempt to deliver a report</dfn> given an [=aggregatable report=]
|report|:
1. Let |url| be the result of [=obtaining a reporting endpoint=] given
    |report|'s [=aggregatable report/reporting origin=] and |report|'s
    [=aggregatable report/api=].
1. Let |data| be the result of [=serializing an aggregatable report=] given
    |report|.
1. If |data| is an error, [=list/remove=] |report| from the [=aggregatable
    report cache=].

    Issue: Do we need to queue this task?
1. Let |request| be the result of [=creating a report request=] given |url| and
    |data|.
1. [=Queue a task=] to [=fetch=] |request| with [=fetch/processResponse=] being
    the following steps:
    1. Let |shouldRetry| be an [=implementation-defined=] [=boolean=]. The value
        should be false if no error occurred.
    1. If |shouldRetry| is true:
        1. Set |report|'s [=aggregatable report/report time=] to the [=current
            wall time=] plus an [=implementation-defined=] non-negative
            [=duration=].
        1. Set |report|'s [=aggregatable report/queued=] value to false.
    1. Otherwise, [=list/remove=] |report| from the [=aggregatable report
        cache=].

</div>

<div algorithm>
To <dfn>obtain a reporting endpoint</dfn> given an [=origin=] |reportingOrigin|
and [=context type=] |api|, perform the following steps. They return a [=URL=].
1. [=Assert=]: |reportingOrigin| is a [=potentially trustworthy origin=].
1. Let |path| be the [=string/concatenation=] of
    «"<code>[[RFC8615|.well-known]]/private-aggregation/report-</code>", |api|».

    Issue(67): Register this well-known directory.
1. Let |base| be the result on running the [=URL parser=] on the [=serialization
    of an origin|serialization=] of |reportingOrigin|.
1. [=Assert=]: |base| is not failure.
1. Let |result| be the result of running the [=URL parser=] on |path| with
    |base|.
1. [=Assert=]: |result| is not failure.
1. Return |result|.

</div>

<div algorithm>
To <dfn>create a report request</dfn> given a [=URL=] |url| and a [=byte
sequence=] |body|:
1. Let |request| be a new [=request=] with the following properties:
    :   [=request/method=]
    ::  "`POST`"
    :   [=request/URL=]
    ::  |url|
    :   [=request/header list=]
    ::  «("`Content-Type`", "`application/json`")»
    :   [=request/unsafe-request flag=]
    ::  set
    :   [=request/body=]
    ::  |body|
    :   [=request/client=]
    ::  `null`
    :   [=request/window=]
    ::  "`no-window`"
    :   [=request/service-workers mode=]
    ::  "`none`"
    :   [=request/initiator=]
    ::  ""
    :   [=request/referrer=]
    :: "`no-referrer`"
    :   [=request/mode=]
    ::  "`cors`"
    :   [=request/credentials mode=]
    ::  "`omit`"
    :   [=request/cache mode=]
    ::  "`no-store`"
1. Return |request|.

</div>

Serializing reports {#serializing-reports}
------------------------------------------

Note: This section is largely copied from the
    <a href="https://wicg.github.io/attribution-reporting-api/">Attribution
    Reporting API spec</a>, adapting as necessary.

<div algorithm>
To <dfn>serialize an aggregatable report</dfn> given an [=aggregatable report=]
|report|, perform the following steps. They return a [=byte sequence=] or an
error.
1. Let |aggregationServicePayloads| be the result of [=obtaining the aggregation
    service payloads=] given |report|.
1. If |aggregationServicePayloads| is an error, return
    |aggregationServicePayloads|.
1. Let |data| be an [=ordered map=] of the following key/value pairs:
    : "`aggregation_coordinator_origin`"
    :: |report|'s [=aggregatable report/aggregation coordinator=],
        [=serialization of an origin|serialized=].
    : "`aggregation_service_payloads`"
    :: |aggregationServicePayloads|
    : "`shared_info`"
    :: The result of [=obtaining a report's shared info=] given |report|.
1. Let |debugKey| be |report|'s [=aggregatable report/debug details=]'s [=debug
    details/key=].
1. If |debugKey| is not null, [=map/set=] |data|["`debug_key`"] to |debugKey|.
1. Let |contextId| be |report|'s [=aggregatable report/context ID=].
1. If |contextId| is not null, [=map/set=] |data|["`context_id`"] to
    |contextId|.
1. Return the [=byte sequence=] resulting from executing [=serialize an infra
    value to JSON bytes=] on |data|.

</div>

<div algorithm>
To <dfn>obtain the aggregation service payloads</dfn> given an [=aggregatable
report=] |report|, perform the following steps. They return a [=list=] of
[=maps=] or an error.
1. Let |publicKeyTuple| be the result of [=obtaining the public key for
    encryption=] given |report|'s [=aggregatable report/aggregation
    coordinator=].
1. If |publicKeyTuple| is an error, return |publicKeyTuple|.
1. Let (|pkR|, |keyId|) be |publicKeyTuple|.
1. Let |plaintextPayload| be the result of [=obtaining the plaintext payload=]
    given |report|.
1. Let |sharedInfo| be the result of [=obtaining a report's shared info=] given
    |report|.
1. Let |encryptedPayload| be the result of [=encrypting the payload=] given
    |plaintextPayload|, |pkR| and |sharedInfo|.
1. If |encryptedPayload| is an error, return |encryptedPayload|.
1. Let |aggregationServicePayloads| be a new [=list=].
1. Let |aggregationServicePayload| be an [=ordered map=] of the following
    key/value pairs:
    : "`key_id`"
    :: |keyId|
    : "`payload`"
    :: |encryptedPayload|, [=forgiving-base64 encode|base64 encoded=]
1. If |report|'s [=aggregatable report/debug details=]'s [=debug details/
    enabled=] field is true:
    1. [=map/Set=] |aggregationServicePayload|[`debug_cleartext_payload`] to
        |plaintextPayload|, [=forgiving-base64 encode|base64 encoded=].
1. [=list/Append=] |aggregationServicePayload| to |aggregationServicePayloads|.
1. Return |aggregationServicePayloads|.

</div>

<div algorithm>
To <dfn>obtain the public key for encryption</dfn> given an [=aggregation
coordinator=] |aggregationCoordinator|, perform the following steps. They return
a [=tuple=] consisting of a public key and a [=string=], or an error.

1. Let |url| be a new [=URL record=].
1. Set |url|'s [=url/scheme=] to |aggregationCoordinator|'s [=origin/scheme=].
1. Set |url|'s [=url/host=] to |aggregationCoordinator|'s [=origin/host=].
1. Set |url|'s [=url/port=] to |aggregationCoordinator|'s [=origin/port=].
1. Set |url|'s [=url/path=]  to «"`.well-known`", "`aggregation-service`",
    "`v1`", "`public-keys`"».
1. Return an [=implementation-defined=] [=tuple=] consisting of a public key
    from |url| and a [=string=] that should uniquely identify the public key or,
    in the event that the user agent failed to obtain the public key from |url|,
    an error. This step may be asynchronous.

Issue: Specify this in terms of [=fetch=]. Add details about which encryption
    standards to use, length requirements, etc.

Note: The user agent is encouraged to enforce regular key rotation. If there are
    multiple keys, the user agent can independently pick a key uniformly at
    random for every encryption operation.

</div>

<div algorithm>
To <dfn>obtain the plaintext payload</dfn> given an [=aggregatable report=]
    |report|, perform the following steps. They return a [=byte sequence=].
1. Let |payloadData| be a new [=list=].
1. Let |contributions| be |report|'s [=aggregatable report/contributions=].
1. Let |maxContributions| be |report|'s [=aggregatable report/max
    contributions=].
1. [=Assert=]: |contributions|' [=list/size=] is not greater than
    |maxContributions|.
1. [=iteration/While=] |contributions|' [=list/size=] is less than
    |maxContributions|:
    1. Let |nullContribution| be a new {{PAHistogramContribution}} with the
        items:
        : {{PAHistogramContribution/bucket}}
        :: 0
        : {{PAHistogramContribution/value}}
        :: 0
        : {{PAHistogramContribution/filteringId}}
        :: 0
    1. [=list/Append=] |nullContribution| to |contributions|.

    Note: This padding protects against the number of contributions being leaked
        through the encrypted payload size, see discussion
        [below](#protecting-against-leaks-via-payload-size).
1. [=list/iterate|For each=] |contribution| of |report|'s [=aggregatable report/
    contributions=]:
    1. Let |filteringIdMaxBytes| be |report|'s [=aggregatable report/filtering
        id max bytes=].
    1. [=Assert=]: |contribution|["{{PAHistogramContribution/filteringId}}"]
        is [=set/contained=] in [=the exclusive range|the range=] 0 to
        256<sup>|filteringIdMaxBytes|</sup>, exclusive.
    1. Let |contributionData| be an [=ordered map=] of the following key/value
        pairs:
        : "`bucket`"
        :: The result of [=encoding an integer for the payload=] given
            |contribution|["{{PAHistogramContribution/bucket}}"] and 16.
        : "`value`"
        :: The result of [=encoding an integer for the payload=] given
            |contribution|["{{PAHistogramContribution/value}}"] and 4.
        : "`id`"
        :: The result of [=encoding an integer for the payload=] given
            |contribution|["{{PAHistogramContribution/filteringId}}"] and
            |filteringIdMaxBytes|.
    1. [=list/Append=] |contributionData| to |payloadData|.
1. Let |payload| be an [=ordered map=] of the following key/value pairs:
    : "`data`"
    :: |payloadData|
    : "`operation`"
    :: "`histogram`"
1. Return the [=byte sequence=] resulting from [[!RFC8949|CBOR encoding]]
    |payload|.

</div>

<div algorithm>
To <dfn>encrypt the payload</dfn> given a [=byte sequence=] |plaintextPayload|,
public key |pkR| and a [=string=] |sharedInfo|, perform the following steps.
They return a [=byte sequence=] or an error.

1. Let |info| be the result of [=UTF-8 encoding=] the [=string/concatenation=]
    of « "`aggregation_service`", |sharedInfo| ».
1. Let (|kem_id|, |kdf_id|, |aead_id|) be (0x0020, 0x0001, 0x0003).

    Note: The ciphersuite triple above is composed of [[RFC9180|HPKE]]
        [[RFC9180#name-algorithm-identifiers|algorithm identifiers]], specifying
        the [[RFC9180#name-key-encapsulation-mechanism|KEM]] as DHKEM(X25519,
        HKDF-SHA256), the [[RFC9180#name-key-derivation-functions-kd|KDF]]
        function as HKDF-SHA256 and the
        [[RFC9180#name-authenticated-encryption-wi|AEAD]] function as
        ChaCha20Poly1305.
1. Let (|enc|, |hpkeContext|) be the result of setting up an [[RFC9180|HPKE]]
    [[RFC9180#name-encryption-to-a-public-key|sender's context]] by calling
    `SetupBaseS()` with a public key |pkR|, application-supplied information
    |info|, KEM |kem_id|, KDF |kdf_id|, and AEAD |aead_id|. If this operation
    fails, return an error.

     Note: For clarity, we explicitly passed the KEM, KDF, and AEAD identifiers
     to `SetupBaseS()` above, even though RFC9180 omits the parameters from its
     pseudocode.
1. Let |aad| be \`\` (an empty [=byte sequence=]).
1. Let |ciphertext| be the result of
    [[RFC9180#name-encryption-and-decryption|sealing]] the payload by calling
    `ContextS.Seal()` on the |hpkeContext| object with additional authenticated
    data |aad| and plaintext |plaintextPayload|. If this operation fails, return
    an error.
1. Let |encryptedPayload| be the concatenation of the [=byte sequences=] «
    |enc|, |ciphertext| ».

    Note: The length of the encapsulated symmetric key <var ignore>enc</var>
     generated by our chosen KEM is exactly 32 bytes, as shown in RFC9180's
     table of [[RFC9180#name-key-encapsulation-mechanism|KEM IDs]].
1. Return the [=byte sequence=] |encryptedPayload|.

</div>

<div algorithm>
To <dfn>encode an integer for the payload</dfn> given an integer |intToEncode|
and an integer |byteLength|, return the representation of |intToEncode| as a
big-endian [=byte sequence=] of length |byteLength|, left padding with zeroes as
necessary.

</div>

<div algorithm>
To <dfn>obtain a report's shared info</dfn> given an [=aggregatable report=]
|report|, perform the following steps. They return a [=string=].
1. Let |scheduledReportTime| be the [=duration from=] the [=UNIX epoch=] to
    |report|'s [=aggregatable report/original report time=].
1. Let |sharedInfo| be an [=ordered map=] of the following key/value pairs:
    : "`api`"
    :: |report|'s [=aggregatable report/api=]
    : "`report_id`"
    :: |report|'s [=aggregatable report/report ID=]
    : "`reporting_origin`"
    :: The [=serialization of an origin|serialization=] of |report|'s
        [=aggregatable report/reporting origin=]
    : "`scheduled_report_time`"
    :: The number of seconds in |scheduledReportTime|, rounded down to the
        nearest number of whole seconds and [=serialize an integer|serialized=]
    : "`version`"
    :: "`1.0`"
1. Return the result of [=serializing an infra value to a json string=] given
    |sharedInfo|.

</div>

Budgeting {#budgeting}
------------------------------------------------

<div algorithm>
To <dfn>check that a contribution's named budget exists</dfn> with a
{{PAHistogramContribution}} |contribution| and a [=scoping details=]
|scopingDetails|, perform the following steps. They return a boolean.

1. Let |namedBudget| be |contribution|'s
    {{PAHistogramContribution/namedBudget}}.
1. If |namedBudget| is null, return true.
1. Let |batchingScope| be the result of running |scopingDetails|' [=scoping
    details/get batching scope steps=].
1. If [=named budget ledgers map=][|batchingScope|] does not [=map/exist=],
    return false.

    Note: This happens when |contribution| references a named budget, but no
    named budgets have been successfully reserved by a call to
    {{PrivateAggregation/reserveNamedBudgets()}}.
1. Let |ledgers| be [=named budget ledgers map=][|batchingScope|].
1. [=Assert=] that |ledgers| is not [=list/empty=].
1. [=list/For each=] |ledger| of |ledgers|:
    1. If |ledger|[|namedBudget|] does not [=map/exist=], return false.

        Note: This happens when a script did successfully call
        {{PrivateAggregation/reserveNamedBudgets()}}, but none of the named
        budgets reserved by that call were |namedBudget|.
1. Return true.

</div>

User-agent automation {#user-agent-automation}
==============================================

A user agent holds a boolean <dfn>automation local testing mode enabled</dfn>
(default false).

For the purposes of user-agent automation and website testing, this document
defines the below [[WebDriver]] [=extension commands=] to control the API
configuration.

Set local testing mode {#set-local-testing-mode}
------------------------------------------------

<figure id="table-webdriver-setlocaltestingmode" class="table">
    <table class="data">
        <thead>
            <tr>
                <th>HTTP Method</th>
                <th>URI Template</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>POST</td>
                <td>`/session/{session id}/private-aggregation/`<dfn
                    noexport>`localtestingmode`</dfn></td>
            </tr>
        </tbody>
    </table>
</figure>

<div algorithm="remote end steps">
The <a spec="webdriver2">remote end steps</a> given <var ignore>session</var>,
<var ignore>URL variables</var> and |parameters| are:

1. If |parameters| is not a JSON-formatted [[ECMASCRIPT#sec-objects|Object]],
    return a [=error|WebDriver error=] with [=error code=] [=invalid argument=].
1. Let |enabled| be the result of [=getting a property=] named `"enabled"` from
    |parameters|.
1. If |enabled| is {{undefined}} or is not a boolean, return a [=error|WebDriver
    error=] with [=error code=] [=invalid argument=].
1. Set [=automation local testing mode enabled=] to |enabled|.
1. Return [=success=] with data `null`.

Note: Without this, [=aggregatable reports=] would be subject to delays, making
    testing difficult.

</div>

Privacy considerations {#privacy-considerations}
================================================

<em>This section is non-normative.</em>

Cross-site information disclosure {#cross-site-information-disclosure}
----------------------------------------------------------------------

This API lets isolated contexts with access to cross-site data (i.e. <a
href="https://wicg.github.io/shared-storage/">Shared Storage</a> worklets/<a
href="https://wicg.github.io/turtledove/">Protected Audience</a> script runners)
send aggregatable reports over the network.

Aggregatable reports contain encrypted high entropy cross-site information, in
the form of key-value pairs (i.e. contributions to a histogram). The information
embedded in the contributions is arbitrary but can include things like browsing
history and other cross-site activity. The API aims to protect this information
from being passed from one site to another.

### Restricted contribution processing ### {#restricted-contribution-processing}

The histogram contributions are not exposed directly. Instead, they are
encrypted so that they can only be processed by a trusted aggregation service.
This trusted aggregation service sums the values across the reports for each key
and adds noise to each of these values to produce ‘summary reports’.

The output of that processing will be an aggregated, noised histogram. The
service ensures that any report can not be processed multiple times. Further,
information exposure is limited by contribution budgets on the user agent. In
principle, this framework can support specifying a noise parameter which
satisfies differential privacy.

### Unencrypted metadata ### {#unencrypted-metadata}

These reports also expose a limited amount of metadata, which is not based on
cross-site data. The recipient of the report may also be able to observe
side-channel information such as the time when the report was sent, or IP
address of the sender.

### Protecting against leaks via the number of reports ### {#protecting-against-leaks-via-the-number-of-reports}

However, the number of reports with the given metadata could expose some
cross-site information. To protect against this, the API delays sending reports
by a randomized amount of time to make it difficult to determine whether a
report was sent or not from any particular event. In the case that a
[=pre-specified report parameters/context ID=] is supplied, a non-default
[=pre-specified report parameters/filtering ID max bytes=] is specified, or a
non-default [=pre-specified report parameters/max contributions=] is specified,
the API makes the number of reports sent deterministic (sending 'null reports'
if necessary — each containing only a contribution with a value of 0 in the
payload). Additional mitigations may also be possible in the future, e.g. adding
noise to the report count.

### Protecting against leaks via payload size ### {#protecting-against-leaks-via-payload-size}

The length of the encrypted payload could additionally expose some cross-site
information, namely the number of contributions present in the plaintext
payload. To eliminate this side channel, Private Aggregation ensures that
payloads contain a predetermined number of contributions prior to encryption,
potentially truncating or padding with null contributions to match the target.

When [=pre-specified report parameters/max contributions=] is non-null, Private
Aggregation uses it to inform the target number of contributions. Otherwise, the
target number is drawn from [=default maxContributions by API=] based on the
caller's [=context type=].

### Temporary debugging mechanism ### {#temporary-debugging-mechanism}

The {{PrivateAggregation/enableDebugMode()}} method allows for many of the
protections of this API to be bypassed to ease testing and integration.
Specifically, the contents of the payload, i.e. the histogram contributions, are
revealed in the clear when the debug mode is enabled. Optionally, a debug key
can also be set to associate the report with the calling context. In the future,
this mechanism will only be available for callers that are eligible to set
third-party cookies. In that case, the API caller already has the ability to
communicate information cross-site.

Issue(57): Tie {{PrivateAggregation/enableDebugMode()}} to third-party cookie
    eligibility.

### Privacy parameters ### {#privacy-parameters}

The amount of information exposed by this API is a product of the privacy
parameters used (e.g. contribution limits and the noise distribution used in the
aggregation service). While we aim to minimize the amount of information
exposed, we also aim to support a wide range of use cases. The privacy
parameters are left [=implementation-defined=] to allow different and evolving
choices in the tradeoffs between information exposure and utility.

Clearing site data {#clearing-site-data}
----------------------------------------

The [=aggregatable report cache=] as well as any contribution history data
stored for the [=query the budget=] algorithm contain data about a user’s web
activity. As such, user controls to delete this data are required, see [clearing
storage](#clearing-storage).

On the other hand, the [=contribution cache=], the [=debug scope map=] and the
[=pre-specified report parameters map=] only contain short-lived data tied to
particular [=batching scopes=] and [=debug scopes=], so controls are not
required.

Reporting delay concerns {#reporting-delay-concerns}
----------------------------------------------------

Delaying sending reports after API invocation can enable side-channel leakage in
some situations.

### Cross-network reporting origin leakage ### {#cross-network-reporting-origin-leakage}

A report may be stored while the browser is connected to one network but sent
while the browser is connected to a different network, potentially enabling
cross-network leakage of the reporting origin.

Example: A user runs the browser with a particular browsing profile on their
home network. An aggregatable report with a particular reporting origin is
stored with a report time in the future. After the report time is reached, the
user runs the browser with the same browsing profile on their employer’s
network, at which point the browser sends the report to the reporting origin.
Although the report itself may be sent over HTTPS, the reporting origin may be
visible to the network administrator via DNS or the TLS client hello (which can
be mitigated with ECH). Some reporting origins may be known to operate only or
primarily on sensitive sites, so this could leak information about the user’s
browsing activity to the user’s employer without their knowledge or consent.

Possible mitigations include:

1. Only sending reports with a given reporting origin when the browser has
    already made a request to that origin on the same network: This prevents the
    network administrator from gaining additional information from the Private
    Aggregation API. However, it increases report loss and report delays, which
    reduces the utility of the API for the reporting origin. It might also
    increase the effectiveness of timing attacks, as the origin may be able to
    better link the report with the user’s request that allowed the report to be
    released.
1. Send reports immediately: This reduces the likelihood of a report being
    stored and sent on different networks. However, it increases the likelihood
    that the reporting origin can correlate the original API invocation to the
    report being sent, which weakens the privacy controls of the API, see
    [Protecting against leaks via the number of
    reports](#protecting-against-leaks-via-the-number-of-reports).
1. Use a trusted proxy server to send reports: This effectively moves the
    reporting origin into the report body, so only the proxy server would be
    visible to the network administrator.
1. Require [[RFC8484|DNS over HTTPS]]: This effectively hides the reporting
    origin from the network administrator, but is likely impractical to enforce
    and is itself perhaps circumventable by the network administrator, e.g. by
    monitoring IP addresses instead.

### User-presence tracking ### {#user-presence-tracking}

The browser only tries to send reports while it is running and while it has
internet connectivity (even without an explicit check for connectivity,
naturally the report will fail to be sent if there is none), so receiving or not
receiving a ([=serializing an aggregatable report|serialized=]) [=aggregatable
report=] at the [=aggregatable report/original report time=] leaks information
about the user’s presence. Additionally, because the report request inherently
includes an IP address, this could reveal the user’s IP-derived location to the
reporting origin, including at-home vs. at-work or approximate real-world
geolocation, or reveal patterns in the user’s browsing activity.

Possible mitigations include:

1. Send reports immediately: This effectively eliminates the presence tracking,
    as the original request made to the reporting origin is in close temporal
    proximity to the report request. However, it increases the likelihood that
    the reporting origin can correlate the original API invocation to the report
    being sent, which weakens the privacy controls of the API, see [Protecting
    against leaks via the number of
    reports](#protecting-against-leaks-via-the-number-of-reports).
1. Send reports immediately to a trusted proxy server, which would itself apply
    additional delay: This would effectively hide both the user’s IP address and
    their online-offline presence from the reporting origin.

Security considerations {#security-considerations}
================================================

<em>This section is non-normative.</em>

Same-origin policy {#same-origin-policy}
----------------------------------------

Writes to the [=aggregatable report cache=], [=contribution cache=], [=debug
scope map=] and [=pre-specified report parameters map=] are attributed to the
reporting [=origin=] and the data included in any report with a given reporting
[=origin=] are generated with only data from that [=origin=].

One notable exception is the [=query the budget=] algorithm which is
[=implementation-defined=] and can consider contribution history from other
[=origins=]. For example, the algorithm could consider all history from a
particular [=site=]. This would be an explicit relaxation of the same-origin
policy as multiple origins would be able to influence the API's behavior. One
particular risk of these kinds of shared limits is the introduction of denial of
service attacks, where a group of origins could collude to intentionally consume
all available budget, causing subsequent origins to be unable to access the API.
This trades off security for privacy, in that the limits are there to reduce the
efficacy of many origins colluding together to violate privacy. However, this
security risk is lessened if the set of origins limited are all [=same site=].
[=User agents=] should consider these tradeoffs when choosing the [=query the
budget=] algorithm.

Protecting the histogram contributions {#protecting-the-histogram-contributions}
--------------------------------------------------------------------------------

As discussed [above](#restricted-contribution-processing), the processing of
histogram contributions is limited to protect privacy. This limitation relies on
only the trusted aggregation service being able to access the unencrypted
histogram contributions.

To ensure this, this API uses [[RFC9180|HPKE]], a modern encryption
specification. Additionally, each [=user agent=] is encouraged to require
regular key rotation by the aggregation service. This limits the amount of data
encrypted with the same key and thus the amount of vulnerable data in the case
of a key being compromised.

While not specified here, each [=user agent=] is strongly encouraged to consider
the security of any aggregation service design before allowing its public keys
to be returned by [=obtain the public key for encryption=].
